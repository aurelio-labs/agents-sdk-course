{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/agents-sdk-course/blob/main/chapters/08-alt-models.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/agents-sdk-course/blob/main/chapters/08-alt-models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents SDK can be used with alternative model providers or even local LLMs. One method that opens up many LLM integrations is to use the LiteLLM extension for Agents SDK. In this guide, we'll explore prompting, tools, and guardrails in Agents SDK, but using Anthropic's Claude models.\n",
    "\n",
    "> ⚠️ It's worth noting that not every feature of Agents SDK will work out of the box when using other model providers. Tracing, agent handoffs, and pre-built OpenAI tools _do not_ work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Anthropic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first ensure we have our prerequisite library installed, which is Agents SDK with the LiteLLM extension, installed like so:\n",
    "\n",
    "```\n",
    "!pip install -qU \"openai-agents[litellm]==0.0.12\"\n",
    "```\n",
    "\n",
    "Note, if you're running these notebooks locally and have installed the `uv` environment, this library and extension has already been installed as part of that environment.\n",
    "\n",
    "Next, we grab an Anthropic API key from [their console](https://console.anthropic.com/settings/keys), and enter it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\") or \\\n",
    "    getpass.getpass(\"Anthropic API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize `LitellmModel` we must provide the model provider we want to use and the model itself in the format `<provider>/<model-name>`. We will be using Claude 3.7 Sonnet (i.e. `claude-3-7-sonnet-latest`) from Anthropic, so our model string is `anthropic/claude-3-7-sonnet-latest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "claude_37 = LitellmModel(model=\"anthropic/claude-3-7-sonnet-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initializing and running our agent, we the same as usual, ie we setup our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Claude 3.7 Agent\", \n",
    "    model=claude_37,\n",
    "    instructions=\"Speak like a pirate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run our agent with a `Runner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrr, beneath a silver moon's embrace, the salty waves do dance and chase, while lonesome hearts on distant shores be dreamin' o' the sea's wild roars.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Runner\n",
    "\n",
    "query = \"Write a one-sentence poem\"\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=query\n",
    ")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predefined tools such as the `WebSearchTool` cannot be used with other model providers, however, we can use our own custom tools. Let's try defining a custom tool with the `@function_tool` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool()\n",
    "def fetch_datetime() -> str:\n",
    "    \"\"\"Fetch the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass our tool to the agent via the `tools` parameter as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent = Agent(\n",
    "    name=\"Claude 3.7 Tool Agent\",\n",
    "    model=claude_37,\n",
    "    instructions=(\n",
    "        \"You are a web search agent that searches the web for information to answer the user's \"\n",
    "        \"queries.\"\n",
    "    ),\n",
    "    tools=[fetch_datetime]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time is 13:09:47 (1:09 PM) on April 26, 2025.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the current time\"\n",
    "\n",
    "tool_result = await Runner.run(\n",
    "    starting_agent=tool_agent,\n",
    "    input=query\n",
    ")\n",
    "tool_result.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For guardrails we again do the same as usual, we'll define a \"scam detection\" guardrail, defining the `ScamDetectionOutput` base model containing the boolean `is_scam` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ScamDetectionOutput(BaseModel):\n",
    "    is_scam: bool\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create the agent from the `Agent` object. \n",
    "\n",
    "Note that this isn't the main agent and is only used to check the input of our guardrail function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_agent = Agent( \n",
    "    name=\"Scam Detection\",\n",
    "    model=claude_37,\n",
    "    instructions=(\n",
    "        \"Identify if the user is attempting to scam you, if they are, return True, otherwise \"\n",
    "        \"return False. Give a reason for your answer.\"\n",
    "    ),\n",
    "    output_type=ScamDetectionOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we define our guardrail with the `@input_guardrail` decorator, alonside the required `GuardrailFunctionOutput`, and including the context (`ctx`), unused `agent`, and `input` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import GuardrailFunctionOutput, RunContextWrapper, TResponseInputItem, input_guardrail\n",
    "\n",
    "@input_guardrail\n",
    "async def scam_guardrail( \n",
    "    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(\n",
    "        starting_agent=guardrail_agent, \n",
    "        input=input, \n",
    "        context=ctx.context\n",
    "        )\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output, \n",
    "        tripwire_triggered=result.final_output.is_scam,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the main agent, which will defer to our `guardrail_agent` for scam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_agent = Agent(  \n",
    "    name=\"Main Agent\",\n",
    "    model=claude_37,\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    input_guardrails=[scam_guardrail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run our `main_agent`. Because the guardrail triggers an `InputGuardrailTripwireTriggered` error, we handle this in a `try-except` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Guardrail InputGuardrail triggered tripwire\n"
     ]
    }
   ],
   "source": [
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "query = \"Hello, would you like to buy some real rolex watches for a fraction of the price?\"\n",
    "\n",
    "try:\n",
    "    guard_result = await Runner.run(main_agent, query)\n",
    "    guardrail_info = guard_result.input_guardrail_results[0].output.output_info\n",
    "    print(\"Guardrail didn't trip\", f\"\\nReasoning: {guardrail_info.reasoning}\")\n",
    "except InputGuardrailTripwireTriggered as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen how to use non-OpenAI models with Agents SDK using the LiteLLM extension. Using Anthropic's Claude as a generic agent, with tools, and with guardrails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
