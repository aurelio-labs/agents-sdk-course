{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/agents-sdk-course/blob/main/chapters/06-streaming.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/agents-sdk-course/blob/main/chapters/06-streaming.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Streaming allows for a more human response from our LLMs, when streaming, we can obtain chunks of data at a time, similar to how we would talk. Then we will move on to creating a system where the LLM outputs updates in the events that occour during the run time. This will keep the user updated on the LLM's activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    \"openai-agents==0.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to get a `OPENAI_API_KEY` set up, for this you will need to create an account on [OpenAI](https://platform.openai.com/api-keys) and grab your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
    "    getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Text Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will quickly cover the basics to stream text straight from an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the `Agent` class and define our agent object, here we will only need to do the basic settup as we did in previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Streamer Agent\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run our agent asynchronously and with streaming, we will use the `run_streamed` method rather than the default `run` method, allowing us to stream tokens or events to our user/console as soon as they are received from OpenAI.\n",
    "\n",
    "Now we can create a for loop that checks for any events happening, and then if the event is a chunk of text via the `ResponseTextDeltaEvent` we want to force print that to the console using `flush`. We also use `end=\"\"` to avoid printing each individual token on a new line.\n",
    "\n",
    "When you run this code you should see tokens being streamed to the output below, rather than being printed in a single large chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stock market crash of 2008 was primarily caused by the collapse of the housing bubble in the United States and the resulting financial crisis. Several key factors contributed to this crash:\n",
      "\n",
      "1. **Housing Bubble and Subprime Mortgages**: Leading up to 2008, there was a significant increase in housing prices fueled by speculative investments and easy credit. Banks and financial institutions issued a large number of subprime mortgages—loans to borrowers with poor credit histories—many of which were risky and likely to default.\n",
      "\n",
      "2. **Securitization of Mortgages**: These risky mortgages were bundled into complex financial products called mortgage-backed securities (MBS) and collateralized debt obligations (CDOs). These securities were sold to investors worldwide, spreading the risk throughout the financial system.\n",
      "\n",
      "3. **High Leverage and Risky Financial Practices**: Financial institutions used high leverage (borrowed money) to amplify their investments in these mortgage-related securities, increasing their vulnerability to losses.\n",
      "\n",
      "4. **Decline in Housing Prices**: When housing prices started to fall in 2006-2007, many homeowners defaulted on their mortgages. This led to significant losses on mortgage-backed securities, undermining the financial health of banks and investors.\n",
      "\n",
      "5. **Loss of Confidence and Credit Crunch**: As banks faced huge losses, trust in the financial system eroded. Institutions became unwilling to lend to each other, causing a credit freeze that impacted businesses and consumers.\n",
      "\n",
      "6. **Bank Failures and Government Interventions**: Major financial institutions such as Lehman Brothers collapsed, and others required government bailouts to survive, further shaking investor confidence.\n",
      "\n",
      "All these factors combined resulted in a severe stock market crash and a global economic downturn known as the Great Recession. The crisis highlighted weaknesses in financial regulation and risk management that were subsequently addressed in reforms like the Dodd-Frank Act."
     ]
    }
   ],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from agents import Runner\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "    agent,\n",
    "    input=\"Tell me what caused the stock market to crash in 2008.\"\n",
    ")\n",
    "\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Event Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to stream event information. This can include anything from an agent change, to a tool call, or even the output finally being ready to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a function using the `function_tool` decorator.\n",
    "\n",
    "This tool will be a simple time tool that will return the current time in a string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool()\n",
    "async def fetch_time() -> str:\n",
    "    \"\"\"Fetch the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want a lower level agent that has access to this tool, we can make this by defining a new agent from the `Agent` class as we did previously. Whilst also supplying instructions to make sure the agent is aware of the role it plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agent = Agent(\n",
    "    name=\"Time-Agent\",\n",
    "    instructions=(\n",
    "        \"You are a time agent that fetches the current time. Make sure when returning \"\n",
    "        \"your response you include the agent that provided the information along with \"\n",
    "        \"any additional tool calls used within the agent.\"\n",
    "    ),\n",
    "    tools=[fetch_time],\n",
    "    model='gpt-4.1-mini',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to define our top level agent, and use the agent we defined in the previous step `as_tool`, allowing us to make extra events in our stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_agent = Agent(\n",
    "    name=\"Orchestrator-Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are an orchestrator agent that uses the tools given to you to complete the \n",
    "    user's query.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        time_agent.as_tool(\n",
    "            tool_name=\"Time-Agent\",\n",
    "            tool_description=\"Fetch the current time\",\n",
    "        )\n",
    "    ],\n",
    "    model='gpt-4.1-mini',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `run_streamed` method from our `Runner` to begin the events.\n",
    "\n",
    "Then we can use the example given from the Agents SDK team to filter through all the event information.\n",
    "\n",
    "Event information can be anything from a handoff, tool call, or even the message output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated from Orchestrator-Agent to Time-Agent\n",
      "-- Tool 'Time-Agent' called with args {\"input\":\"current time\"}\n",
      "-- Tool output: The current time is 12:36 PM on July 11, 2025. This information was provided by the time agent.\n",
      "The current time is 12:36 PM on July 11, 2025."
     ]
    }
   ],
   "source": [
    "from agents import ItemHelpers\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "    orchestrator_agent,\n",
    "    input=\"what time is it?\",\n",
    ")\n",
    "\n",
    "print(\"=== Run starting ===\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"agent_updated_stream_event\": # when a handoff or agent change occurs\n",
    "        print(f\"Agent updated from {event.new_agent.name} to {event.new_agent.tools[0].name}\")\n",
    "        continue\n",
    "    elif event.type == \"run_item_stream_event\": # when items are generated\n",
    "        if event.item.type == \"tool_call_item\": # if the item is a tool call\n",
    "            print(f\"-- Tool '{event.item.raw_item.name}' called with args {event.item.raw_item.arguments}\")\n",
    "        elif event.item.type == \"tool_call_output_item\": # if the item is a tool call output\n",
    "            print(f\"-- Tool output: {event.item.output}\")\n",
    "        else:\n",
    "            pass  # ignore everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-sdk-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
