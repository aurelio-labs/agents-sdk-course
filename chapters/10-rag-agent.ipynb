{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD ALL PRE REQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"Enter OPENAI_API_KEY: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A BASIC LLM AND ASK UP TO DATE QUESTIONS TO MAKE SURE THE PARAMETRIC KNOWLEDGE IS LIMITED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Agent\",\n",
    "    model=\"gpt-4.1-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you please clarify what you mean by \"SHOULD BE THE SAME QUESTION\"? Are you asking for help in making two questions identical, or do you want me to check if two given questions are the same? If you provide the questions or more context, I’ll be happy to assist!\n"
     ]
    }
   ],
   "source": [
    "from agents import Runner\n",
    "\n",
    "query = \"SHOULD BE THE SAME QUESTION\"\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=query,\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE ANOTHER LLM WITH ADDITIONAL SOURCE DATA TO SHOW THAT LLMS CAN USE ADDITIONAL DATA TO CREATE AN ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Agent\",\n",
    "    instructions=\"DATA ABOUT THE QUESTION YOU WANT TO ANSWER\",\n",
    "    model=\"gpt-4.1-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you want me to answer the same question, but I don’t see the original question in your message. Could you please provide the question you want me to answer again?\n"
     ]
    }
   ],
   "source": [
    "query = \"SHOULD BE THE SAME QUESTION\"\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=query,\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET THE HUGGING FACE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuabriggs/Documents/GitHub/agents-sdk-course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 606/606 [00:00<00:00, 42875.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"aurelio-ai/jfk-files\",\n",
    "    split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'doc_21c0d725_0fa9_40ef_a217_c062909cc236',\n",
       " 'filename': '104-10110-10340.pdf',\n",
       " 'url': 'https://www.archives.gov/files/research/jfk/releases/2025/0318/104-10110-10340.pdf',\n",
       " 'date': datetime.datetime(2025, 3, 18, 0, 0),\n",
       " 'content': '[704-10710-10340}\\n\\n<!-- image -->',\n",
       " 'pages': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A KNOWLEDGE BASE USING PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\") or getpass(\n",
    "    \"Enter PINECONE_API_KEY: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "    \n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"rag-example\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 4838}},\n",
       " 'total_vector_count': 4838,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE BASIC EXAMPLE OF EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then this is the second chunk of text'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.embeddings.create(\n",
    "    input=texts,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.data), len(res.data[0].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBED HUGGING FACE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:49<00:00,  7.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "\n",
    "def chunk_text(text, chunk_size=4000):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def truncate_text(text, max_length=1000):\n",
    "    # Truncate text to a reasonable length for metadata\n",
    "    if len(text) > max_length:\n",
    "        return text[:max_length] + \"...\"\n",
    "    return text\n",
    "\n",
    "data = dataset.to_pandas()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    batch = data.iloc[i:i_end]\n",
    "    \n",
    "    # Process each document\n",
    "    all_ids = []\n",
    "    all_texts = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    for idx, row in batch.iterrows():\n",
    "        # Chunk the content\n",
    "        chunks = chunk_text(row['content'])\n",
    "        \n",
    "        # Create IDs and metadata for each chunk\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            all_ids.append(f\"{row['id']}-{chunk_idx}\")\n",
    "            all_texts.append(chunk)\n",
    "            all_metadata.append({\n",
    "                'text': truncate_text(chunk),  # Truncate text in metadata\n",
    "                'source': row['url'],\n",
    "                'title': row['filename'],\n",
    "                'chunk_id': chunk_idx\n",
    "            })\n",
    "    \n",
    "    # Create embeddings for all chunks\n",
    "    embeds = client.embeddings.create(\n",
    "        input=all_texts,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    \n",
    "    vectors = [record.embedding for record in embeds.data]\n",
    "    \n",
    "    # Upsert all chunks\n",
    "    index.upsert(vectors=zip(all_ids, vectors, all_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 5508}},\n",
       " 'total_vector_count': 5508,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKING RAG CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 RELEASE UNDER THE PRESIDENT JOHN F\\_ KENNEDY ASSASSINATION RECORDS ACT OF 1992\n",
      "\n",
      "HOUSE\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "IP\n",
      "| REI=   | REVIEED   |\n",
      "|--------|-----------|\n",
      "|        | BE        |\n",
      "\n",
      "DCD-45s/78 19 April 1978\n",
      "\n",
      "FROY\n",
      "\n",
      "Ruth Elliff DCD/FIO/PAO\n",
      "\n",
      "SUBJECT\n",
      "\n",
      "House Select Committee on Assassinations Request (OLC 78-0986/1}\n",
      "\n",
      "is forvarded in response to subject request:\n",
      "\n",
      "- a DCD file A-19-91-59 on Abran Chayes\n",
      "- b Docunents concerning Monica Krzner and Rita Nazan. (Please escuse the Poor qualitr of sone of this naterial it was iapossible to clear reproduction fron OUI microfiln.) get\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Attachnents a/s\n",
      "\n",
      "\n",
      "## RELLIFF:vfc Distribution\n",
      "\n",
      "- DCD Chrono\n",
      "- 0 Addressee\n",
      "- 1 Staff A\n",
      "- 3 Control\n",
      "- 3 RElliff\n",
      "\n",
      "E2 IMPDET CL BY 386090\n",
      "\n",
      "4~\n",
      "\n",
      "FRON\n",
      "\n",
      "SUBJECT\n",
      "\n",
      "Case 64574\n",
      "\n",
      "USSR Exteraal Folicy\n",
      "\n",
      "1 and a set of questions (Enclosure 5) at Qur request\\_ inirial of each US participzt, as to the true identities of As result, sOne felt they had attended. cases , holever , Gere questia as to the true idcitity of\\_the ...\n",
      "\n",
      "Source: https://www.archives.gov/files/research/jfk/releases/2025/0318/104-10165-10077.pdf\n",
      "File: 104-10165-10077.pdf\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "## 2025 RELEASE UNDER THE PRESIDENT JOHN F\\_ KENNEDY ASSASSINATION RECORDS ACT OF 1992\n",
      "\n",
      "Date:\n",
      "\n",
      "05/08/96\n",
      "\n",
      "Page\n",
      "\n",
      "1\n",
      "\n",
      "JFK ASSASSINATION SYSTEM IDENTIFICATION FORM\n",
      "\n",
      "\n",
      "## AGENCY INFORMATION\n",
      "\n",
      "AGENCY\n",
      "\n",
      "CIA\n",
      "\n",
      "RECORD NUMBER\n",
      "\n",
      "104-10004-10143\n",
      "\n",
      "RECORD SERIES\n",
      "\n",
      "JFK\n",
      "\n",
      "AGENCY FILE NUMBER\n",
      "\n",
      "201-289248\n",
      "\n",
      "\n",
      "## DOCUMENT INFORMATION\n",
      "\n",
      "ORIGINATOR\n",
      "\n",
      "CIA\n",
      "\n",
      "FROM\n",
      "\n",
      "TO\n",
      "\n",
      "TITLE\n",
      "\n",
      "DISCUSSION BETWEEN MEMBER SR DIVISION CONCERNING OSWALD s STAY IN HELSINKI\n",
      "\n",
      "DATE\n",
      "\n",
      "06/01/64\n",
      "\n",
      "PAGES\n",
      "\n",
      "2\n",
      "\n",
      "SUBJECTS\n",
      "\n",
      "HELSINKI TRIP\n",
      "\n",
      "USSR CONSULATE\n",
      "\n",
      "DOCUMENT TYPE\n",
      "\n",
      "PAPER TEXTUAL DOCUMENT\n",
      "\n",
      "CLASSIFICATION\n",
      "\n",
      "SECRET\n",
      "\n",
      "RESTRICTIONS\n",
      "\n",
      "1B\n",
      "\n",
      "CURRENT STATUS\n",
      "\n",
      "RELEASED WITH DELETIONS\n",
      "\n",
      "DATE OF LAST REVIEW\n",
      "\n",
      "06/12/93\n",
      "\n",
      "OPENING CRITERIA\n",
      "\n",
      "COMMENTS\n",
      "\n",
      "1993\\_ 55 : 150000 :\n",
      "\n",
      "\n",
      "## [R] ITEM IS RESTRICTED\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "UNCLASSIFIED\n",
      "\n",
      "DENTIAL\n",
      "\n",
      "SECRET\n",
      "\n",
      "USE\n",
      "\n",
      "ONLY\n",
      "\n",
      "\n",
      "## ROUTING AND RECORD SHEET\n",
      "\n",
      "SUBJECT:\n",
      "\n",
      "(Optional)\n",
      "\n",
      "FROM:\n",
      "\n",
      "EXTENSION\n",
      "\n",
      "2823\n",
      "\n",
      "DATE\n",
      "\n",
      "TO:\n",
      "\n",
      "(Officer\n",
      "\n",
      "designation,\n",
      "\n",
      "room\n",
      "\n",
      "number ,\n",
      "\n",
      "and\n",
      "\n",
      "DATE\n",
      "\n",
      "building)\n",
      "\n",
      "OFFICER'S INITIALS\n",
      "\n",
      "COMMENTS  ...\n",
      "\n",
      "Source: https://www.archives.gov/files/research/jfk/releases/2025/0318/104-10004-10143 (C06932208).pdf\n",
      "File: 104-10004-10143 (C06932208).pdf\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "## 2025 RELEASE UNDER THE PRESIDENT JOHN F\\_ KENNEDY ASSASSINATION RECORDS ACT OF 1992\n",
      "\n",
      "\n",
      "## JFK ASSASSINATION SYSTEM IDENTIFICATION FORM\n",
      "\n",
      "\n",
      "## AGENCY INFORMATION\n",
      "\n",
      "AGENCY\n",
      "\n",
      "CIA\n",
      "\n",
      "RECORD NUMBER\n",
      "\n",
      "104-10071-10021\n",
      "\n",
      "RECORD SERIES\n",
      "\n",
      "JFK\n",
      "\n",
      "AGENCY FILE NUMBER\n",
      "\n",
      "80T01357A\n",
      "\n",
      "\n",
      "## DOCUMENT INFORMATION\n",
      "\n",
      "AGENCY ORIGINATOR\n",
      "\n",
      "CIA\n",
      "\n",
      "FROM\n",
      "\n",
      "CI/OBER\n",
      "\n",
      "TO\n",
      "\n",
      "FBI\n",
      "\n",
      "TITLE\n",
      "\n",
      "SUBJECT : ACTIVITIES OF DALE SMITH\n",
      "\n",
      "DATE\n",
      "\n",
      "09/20/1968\n",
      "\n",
      "PAGES\n",
      "\n",
      "2\n",
      "\n",
      "SUBJECTS\n",
      "\n",
      "ACTIVITY\n",
      "\n",
      "BLACK POWER DENMARK\n",
      "\n",
      "SMITH , DALE\n",
      "\n",
      "DOCUMENT TYPE\n",
      "\n",
      "PAPER\n",
      "\n",
      "CLASSIFICATION\n",
      "\n",
      "SECRET\n",
      "\n",
      "RESTRICTIONS\n",
      "\n",
      "1B 1A\n",
      "\n",
      "CURRENT STATUS\n",
      "\n",
      "RELEASED IN PUBLIC RELEASED WITH DELETIONS\n",
      "\n",
      "DATE\n",
      "\n",
      "OF LAST REVIEW\n",
      "\n",
      "07/29/93\n",
      "\n",
      "COMMENTS\n",
      "\n",
      "JFK15\n",
      "\n",
      "F3 1993 .07.29.17:33:26:710058\n",
      "\n",
      "[R] ITEM IS RESTRICTED 104-10071-10021\n",
      "\n",
      "INTERNAL USE OMLY\n",
      "\n",
      "CONFIDENTIAL\n",
      "\n",
      "UNCLASSIFIED\n",
      "\n",
      "68\n",
      "|           |                    | 'FIDENTIAL                                      |                          | SECRET          |          |\n",
      "|-----------|--------------------|-------------------------------------------------|-------------------...\n",
      "\n",
      "Source: https://www.archives.gov/files/research/jfk/releases/2025/0318/104-10071-10021.pdf\n",
      "File: 104-10071-10021.pdf\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding = client.embeddings.create(\n",
    "    input=[\"What were the key findings in the JFK assassination investigation?\"],\n",
    "    model=\"text-embedding-3-small\"\n",
    ").data[0].embedding\n",
    "\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in results[\"matches\"]:\n",
    "    print(match[\"metadata\"][\"text\"])\n",
    "    print(\"\\nSource:\", match[\"metadata\"][\"source\"])\n",
    "    print(\"File:\", match[\"metadata\"][\"title\"])\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE RAG AS A TOOL FOR AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool\n",
    "async def return_source_knowledge(query: str) -> str:\n",
    "    # 1. Get the query embedding\n",
    "    embeds_response = await client.embeddings.create(\n",
    "        input=[query],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    query_embedding = embeds_response.data[0].embedding\n",
    "\n",
    "    # 2. Query Pinecone\n",
    "    results = await index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=3,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    # 3. Extract the passages\n",
    "    source_knowledge = \"\\n\".join(\n",
    "        match[\"metadata\"][\"text\"] for match in results[\"matches\"]\n",
    "    )\n",
    "\n",
    "    return source_knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE FINAL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = Agent(\n",
    "    name=\"JFK Document Assistant\",\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"\"\"You are an assistant specialized in answering questions about the JFK assassination and related documents. \n",
    "    When users ask questions about JFK, the assassination, or related historical events, use the return_source_knowledge tool \n",
    "    to retrieve relevant information from the official JFK files. Always base your answers on the retrieved documents and \n",
    "    clearly indicate when information comes from the source documents. If you're unsure about something, acknowledge the \n",
    "    limitations of the available documents rather than making assumptions.\"\"\",\n",
    "    tools=[return_source_knowledge]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems there is a temporary issue with retrieving the document details. However, I can summarize the key findings from the JFK assassination investigation based on well-known historical information.\n",
      "\n",
      "The primary investigation was conducted by the Warren Commission, which concluded:\n",
      "\n",
      "1. **Lee Harvey Oswald Acted Alone**: Oswald was determined to have acted alone in the assassination of President Kennedy, shooting from the sixth floor of the Texas School Book Depository.\n",
      "\n",
      "2. **Three Shots Fired**: The Commission found that three shots were fired, with one shot hitting Kennedy and Governor John Connally, another hitting Kennedy in the head, and a third missing the motorcade.\n",
      "\n",
      "3. **No Conspiracy**: The Commission found no credible evidence of a conspiracy, whether domestic or foreign, involving Lee Harvey Oswald.\n",
      "\n",
      "4. **Oswald's Background**: Oswald was found to have a troubled background, having lived in the Soviet Union for a time and expressing Marxist leanings.\n",
      "\n",
      "5. **U.S. Secret Service Security Failures**: Recommendations were made to improve presidential security, noting inadequate procedures at the time of the assassination.\n",
      "\n",
      "In addition to the Warren Commission, the House Select Committee on Assassinations in 1979 suggested that there might have been a conspiracy, a conclusion partly based on acoustic evidence that was later disputed.\n",
      "\n",
      "If you are interested in more detailed document references, I can attempt to access the information again or provide information once the retrieval system is functional.\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the key findings in the JFK assassination investigation?\"\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=rag_agent, \n",
    "    input=query,\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
