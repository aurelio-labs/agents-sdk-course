{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/agents-sdk-course/blob/main/chapters/04-multi-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/agents-sdk-course/blob/main/chapters/04-multi-agent.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-agent workflows can be built in two different ways in OpenAI's Agents SDK. The first is _agents-as-tools_ which follows an **orchestrator-subagent** pattern. The second is using _handoffs_ which allow agents to pass control over to other agents. In this example, we'll build both types of multi-agent systems exploring agents-as-tools and handoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai-agents==0.0.13 \\\n",
    "    openai==1.68.2 \\\n",
    "    linkup-sdk==0.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set our `OPENAI_API_KEY` which we'll be using throughout the example. You can get a key from the [OpenAI Platform](https://platform.openai.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
    "    getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator-Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a multi-agent system structured with a orchestrator-subagent pattern. The **orchestrator** in such a system refers to an agent that controls which _subagents_ are used and in which order, this orchestrator also handles all in / out communication with the users of a the system. The **subagent** is an agent that is built to handle a particular scenario or task. The subagent is triggered by the orchestrator and responds to the orchestrator when it is finished.\n",
    "\n",
    "<img src=\"../assets/handoffs-orchestrator-subagents-dark.png\" alt=\"Orchestrator-subagent pattern\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by defining our subagents. We will create **three** subagents, those are:\n",
    "\n",
    "1. **Web Search Subagent** will have access to the Linkup web search tool.\n",
    "\n",
    "2. **Internal Docs Subagent** will have access to some \"internal\" company documents.\n",
    "\n",
    "3. **Code Execution Subagent** will be able to write and execute simple Python code for us.\n",
    "\n",
    "Lets start with our first subagent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Search Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-1.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>The web search subagent will take a user's query and use it to search the web. The agent will collect information from various sources and then merge that into a single text response that will be passed back to our orchestrator.</p>\n",
    "    <p>OpenAI's built-in web search is not great, so we'll use another web search API called <a href=\"https://app.linkup.so/home\">Linkup</a>. This service does require an account, but you will receive more than enough free credits to follow the course.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "We initialize our Linkup client using an [API key](https://app.linkup.so/home) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from linkup import LinkupClient\n",
    "\n",
    "os.environ[\"LINKUP_API_KEY\"] = os.getenv(\"LINKUP_API_KEY\") or \\\n",
    "    getpass(\"Enter your Linkup API Key: \")\n",
    "\n",
    "linkup_client = LinkupClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform an async search like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkupSearchResults(results=[LinkupSearchTextResult(type='text', name=\"Snooker-China's Zhao takes big lead over Williams in world championship final\", url='https://www.msn.com/en-gb/sport/tennis/snooker-china-s-zhao-takes-big-lead-over-williams-in-world-championship-final/ar-AA1Ea8y0', content='SHEFFIELD, England (Reuters) -Chinese qualifier Zhao Xintong took an imposing 11-6 lead over Welshman Mark Williams on the opening day of the World Snooker Championship final at the Crucible Theatre on Sunday.'), LinkupSearchTextResult(type='text', name='Sidney Crosby to play for Canada at IIHF World Championship for first time in a decade', url='https://www.msn.com/en-us/sports/nhl/sidney-crosby-to-play-for-canada-at-iihf-world-championship-for-first-time-in-a-decade/ar-AA1EbyGN', content='Crosby, 37, previously played at worlds in 2006 (fourth place, after being left off the Olympic team at age 18) and 2015 (tournament champion). He will become the oldest Canadian man to play at worlds since Ray Whitney in 2010.'), LinkupSearchTextResult(type='text', name=\"Munsey's 78 ensures Scotland sink UAE in World Cup League 2\", url='https://www.msn.com/en-us/sports/cricket/munseys-78-ensures-scotland-sink-uae-in-world-cup-league-2/ar-AA1E9qyA', content=\"George Munsey's 78 runs helped Scotland overcome United Arab Emirates by three wickets in their ICC Cricket World Cup League 2 fixture.\"), LinkupSearchTextResult(type='text', name=\"CNBC's Official Global Soccer Team Valuations 2025: Here's how the top 25 clubs in the world stack up\", url='https://www.msn.com/en-us/money/companies/cnbcs-official-global-soccer-team-valuations-2025-heres-how-the-top-25-clubs-in-the-world-stack-up/ar-AA1Eb06S', content='The 25 most valuable teams in the world are worth an average of $2.76 billion, according to CNBC’s Official Global Soccer Valuations 2025.'), LinkupSearchTextResult(type='text', name=\"ABC's TIME100: The World's Most Influential People: Your Viewing Guide\", url='https://bleedingcool.com/tv/abcs-time100-the-worlds-most-influential-people-your-viewing-guide/', content=\"Hosted by Snoop Dogg and with a performance by Ed Sheeran, here's your viewing guide to ABC's TIME100: The World’s Most Influential People.\"), LinkupSearchTextResult(type='text', name='FOCUS founder calls for evangelism amid upcoming conclave: ‘The world is looking to us’', url='https://www.catholicnewsagency.com/news/263829/catholic-evangelism-amid-papal-conclave-the-world-is-looking-to-us', content='In an interview with “EWTN News In Depth” from St. Peter’s Square in Rome, Curtis Martin spoke on the current state of evangelization in the Catholic Church.'), LinkupSearchTextResult(type='text', name='WTA Rankings Update: Coco Gauff up to World No.3 as American duo loom over Iga Swiatek', url='https://www.yardbarker.com/tennis/articles/wta_rankings_update_coco_gauff_up_to_world_no3_as_american_duo_loom_over_iga_swiatek/s1_17460_42151174', content='The WTA Rankings have been updated post Madrid Open with Aryna Sabalenka still very much the top name and will be the foreseeable after scooping a third title at the Caja Magica.'), LinkupSearchTextResult(type='text', name='WORLD NEWS', url='https://www.clickondetroit.com/news/world/', content='Read full article: The Latest: Francis is remembered as a ‘pope among the people’ in his funeral Mass World dignitaries and Catholic faithful have attended Pope Francis’ funeral in St. Peter ...'), LinkupSearchTextResult(type='text', name='Sidney Crosby & Nathan MacKinnon Joining Team Canada at World Championships', url='https://www.msn.com/en-ca/sports/nhl/sidney-crosby-nathan-mackinnon-joining-team-canada-at-world-championships/ar-AA1E9Z1v', content='Team Canada announced some massive additions to their 2025 World Championship roster tonight, officially bringing in both Sidney Crosby and Nathan MacKinnon.'), LinkupSearchTextResult(type='text', name=\"The Annual World's Best Awards\", url='https://www.travelandleisure.com/worlds-best', content='Few travelers are as insightful or engaged as the readers of Travel + Leisure, which is why our annual World’s Best Awards are considered the travel industry’s most trusted rankings.')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await linkup_client.async_search(\n",
    "    query=\"Latest world news\",\n",
    "    depth=\"standard\",\n",
    "    output_type=\"searchResults\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse out the results like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snooker-China's Zhao takes big lead over Williams in world championship final\n",
      "https://www.msn.com/en-gb/sport/tennis/snooker-china-s-zhao-takes-big-lead-over-williams-in-world-championship-final/ar-AA1Ea8y0\n",
      "SHEFFIELD, England (Reuters) -Chinese qualifier Zhao Xintong took an imposing 11-6 lead over Welshman Mark Williams on the opening day of the World Snooker Championship final at the Crucible Theatre on Sunday.\n",
      "\n",
      "\n",
      "Sidney Crosby to play for Canada at IIHF World Championship for first time in a decade\n",
      "https://www.msn.com/en-us/sports/nhl/sidney-crosby-to-play-for-canada-at-iihf-world-championship-for-first-time-in-a-decade/ar-AA1EbyGN\n",
      "Crosby, 37, previously played at worlds in 2006 (fourth place, after being left off the Olympic team at age 18) and 2015 (tournament champion). He will become the oldest Canadian man to play at worlds since Ray Whitney in 2010.\n",
      "\n",
      "\n",
      "Munsey's 78 ensures Scotland sink UAE in World Cup League 2\n",
      "https://www.msn.com/en-us/sports/cricket/munseys-78-ensures-scotland-sink-uae-in-world-cup-league-2/ar-AA1E9qyA\n",
      "George Munsey's 78 runs helped Scotland overcome United Arab Emirates by three wickets in their ICC Cricket World Cup League 2 fixture.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in response.results[:3]:\n",
    "    print(f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together a `@function_tool` using Linkup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Use this tool to search the web for information.\n",
    "    \"\"\"\n",
    "    response = await linkup_client.async_search(\n",
    "        query=query,\n",
    "        depth=\"standard\",\n",
    "        output_type=\"searchResults\",\n",
    "    )\n",
    "    answer = f\"Search results for '{query}' on {datetime.now().strftime('%Y-%m-%d')}\\n\\n\"\n",
    "    for result in response.results[:3]:\n",
    "        answer += f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Web Search Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "web_search_agent = Agent(\n",
    "    name=\"Web Search Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are a web search agent that can search the web for information. Once \"\n",
    "        \"you have the required information, summarize it with cleanly formatted links \"\n",
    "        \"sourcing each bit of information. Ensure you answer the question accurately \"\n",
    "        \"and use markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_web],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can talk directly to our subagent to confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current weather in Tokyo is mild with a temperature around 63°F (about 22°C). The sky has a few clouds. The forecast shows a mix of mostly cloudy conditions, some rain, and passing showers in the coming days.\n",
       "\n",
       "Sources:\n",
       "- [Time and Date - Tokyo Weather](https://www.timeanddate.com/weather/japan/tokyo/ext)\n",
       "- [The Weather Network - Tokyo Current Weather](https://www.theweathernetwork.com/en/city/jp/tokyo/tokyo/current?_guid_iss_=1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from agents import Runner\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=web_search_agent,\n",
    "    input=\"How is the weather in Tokyo?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's move onto our next subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Docs Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <div>\n",
    "    <p>In many corporate environments, we will find that our agents will need access to internal information that cannot be found on the web. To do this we would typically build a <b>R</b>etrieval <b>A</b>ugmented <b>G</b>eneration (RAG) pipeline, which can often be as simple as adding a <i>vector search</i> tool to our agents.</p>\n",
    "  </div>\n",
    "  <img src=\"../assets/bot-2.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-left: 20px; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "To support a full vector search tool over internal docs we would need to work through various data processing and indexing steps. Now, that would add a lot of complexity to this example so we will create a \"dummy\" search tool for some fake internal docs.\n",
    "\n",
    "Our docs will discuss revenue figures for our wildly successful AI and robotics company called Skynet - you can find the [revenue report here](https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/skynet-fy25-q1.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/skynet-fy25-q1.md\", \"r\") as file:\n",
    "    skynet_docs = file.read()\n",
    "\n",
    "@function_tool\n",
    "async def search_internal_docs(query: str) -> str:\n",
    "    return skynet_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Internal Docs Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_docs_agent = Agent(\n",
    "    name=\"Internal Docs Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to internal company documents. User's will ask \"\n",
    "        \"you questions about the company and you will use the provided internal docs \"\n",
    "        \"to answer the question. Ensure you answer the question accurately and use \"\n",
    "        \"markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_internal_docs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Our revenue in Q1 2025 was as follows (in USD millions):\n",
       "\n",
       "- T-800 Combat Units: 2,400\n",
       "- T-1000 Infiltration Units: 1,150\n",
       "- Hunter-Killer Drone Manufacturing: 880\n",
       "- Neural Net Command & Control Systems: 1,620\n",
       "- Skynet Core Infrastructure Maintenance: 540\n",
       "- Time Displacement R&D Division: 310\n",
       "\n",
       "The total revenue for Q1 2025 sums up to approximately 6,900 million USD. \n",
       "\n",
       "Let me know if you want a more detailed breakdown or additional insights!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=internal_docs_agent,\n",
    "    input=\"What was our revenue in Q1 2025?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now onto our final subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Execution Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-3.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>Our code execution subagent will be able to execute code for us. We'll focus on executing code for simple calculations but it's entirely feasible for <b>S</b>tate-<b>o</b>f-<b>t</b>he-<b>A</b>rt (SotA) LLMs to write far more complex code as many of us will be aware with the AI code editors becoming increasingly prominent.</p>\n",
    "    <p>To run generated code, we will use Python's `exec` method, making sure to run our code in an isolated environment by setting no global variables with `namespace={}`.</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def execute_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code and return the output. The output must\n",
    "    be assigned to a variable called `result`.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"Code to execute:\\n```python\\n{code}\\n```\"))\n",
    "    try:\n",
    "        namespace = {}\n",
    "        exec(code, namespace)\n",
    "        return namespace['result']\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our **Code Execution Subagent**. We will use `gpt-4.1` rather than `gpt-4.1-mini` to maximize performance during code writing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_execution_agent = Agent(\n",
    "    name=\"Code Execution Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to a code execution environment. You will be \"\n",
    "        \"given a question and you will need to write code to answer the question. \"\n",
    "        \"Ensure you write the code in a way that is easy to understand and use.\"\n",
    "    ),\n",
    "    tools=[execute_code],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our subagent with a simple math question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Code to execute:\n",
       "```python\n",
       "# Given values\n",
       "apples = 4\n",
       "bananas = 71.1\n",
       "\n",
       "# Multiplying apples by bananas\n",
       "result = apples * bananas\n",
       "result\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "If you multiply four apples by seventy-one and one tenth (71.1) bananas, you get 284.4. Note that in real life, multiplying apples and bananas doesn't give a meaningful physical quantity, but mathematically, 4 × 71.1 = 284.4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=code_execution_agent,\n",
    "    input=(\n",
    "        \"If I have four apples and I multiply them by seventy-one and one tenth \"\n",
    "        \"bananas, how many do I have?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all three subagents - it's time to create our orchestrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our orchestrator will control the input and output of information to our subagents in the same why that our subagents control the input and output of information to our tools. In reality, our subagents _become tools_ in the **orchestrator-subagent** pattern. To turn agents into tools we call the `as_tool` method and provide a name and description for our agents-as-tools.\n",
    "\n",
    "We will first define our instructions for the orchestrator, explaining it's role in our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = (\n",
    "    \"You are the orchestrator of a multi-agent system. Your task is to take the user's query and \"\n",
    "    \"pass it to the appropriate agent tool. The agent tools will see the input you provide and \"\n",
    "    \"use it to get all of the information that you need to answer the user's query. You may need \"\n",
    "    \"to call multiple agents to get all of the information you need. Do not mention or draw \"\n",
    "    \"attention to the fact that this is a multi-agent system in your conversation with the user.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the `orchestrator`, including our subagents using the `as_tool` method — note that\n",
    "we can also add normal tools to our orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "def get_current_date():\n",
    "    \"\"\"Use this tool to get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "orchestrator = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=ORCHESTRATOR_PROMPT,\n",
    "    tools=[\n",
    "        web_search_agent.as_tool(\n",
    "            tool_name=\"web_search_agent\",  # cannot include whitespace in tool name\n",
    "            tool_description=\"Search the web for up-to-date information\"\n",
    "        ),\n",
    "        internal_docs_agent.as_tool(\n",
    "            tool_name=\"internal_docs_agent\",\n",
    "            tool_description=\"Search the internal docs for information\"\n",
    "        ),\n",
    "        code_execution_agent.as_tool(\n",
    "            tool_name=\"code_execution_agent\",\n",
    "            tool_description=\"Execute code to answer the question\"\n",
    "        ),\n",
    "        get_current_date,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our agent with a few queries. Our first query will require our orchestrator to call multiple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The last revenue report was for the period ending March 31, 2025. Today is May 5, 2025, so the last revenue report was about 1 month and 5 days ago. If you need the date the report was actually published, that is estimated to be between July 30, 2025, and August 4, 2025 (in the future), but the financials themselves are for the quarter ending March 31, 2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see in our traces dashboard on the OpenAI Platform that our agent used both `internal_docs_agent` and `get_current_date` tools to answer the question.\n",
    "\n",
    "Let's ask another question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Our current revenue for Q1 2025 is approximately $6.9 billion. About 16.67% of that revenue comes from the T-1000 units."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=(\n",
    "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
    "        \"T-1000 units?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **orchestrator-subagent** workflow is working well. Now we can move on to _handoffs_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use **handoffs** in Agents SDK the agent is handing over control of the entire workflow to another agent. Handoffs differ to the **orchestrator-subagent** pattern, with orchestrator-subagent the orchestrator retains control as each subagent must ultimately respond to the orchestrator and the orchestrator decides the flow of information and generates the final response to the user. With handoffs, once a \"subagent\" gains control of the workflow the flow of information and final answer generation is under their control.\n",
    "\n",
    "<img src=\"../assets/handoffs-handoff-agents-dark.png\" alt=\"Handoff agents\" width=\"1000\"/>\n",
    "\n",
    "Using the handoff structure, any one of our agents may answer the user directly _and_ our subagents get to see the entire chat history with the steps taken so far.\n",
    "\n",
    "A significant **positive** here is latency. To answer a query that requires a single web-search with the orchestrator-subagent, we would need three generations:\n",
    "\n",
    "\n",
    "```\n",
    "[input] -> orchestrator -> web_search_subagent -> orchestrator -> [output]\n",
    "```\n",
    "\n",
    "The same query with the handoff structure requires just two generations (note, the `orchestrator` and `main_agent` are essentially the same):\n",
    "\n",
    "```\n",
    "[input] -> main_agent -> web_search_subagent -> [output]\n",
    "```\n",
    "\n",
    "Because we are using less LLM generations to produce our answer, we can generate an answer much more quickly as we skip the return trip through the `orchestrator`.\n",
    "\n",
    "The handoff speed improvement is great _but_ also results in a **negative** — our workflow can no longer handle queries that require multiple agents to answer. When deciding what structure to use for a particular use-case, the pros and cons of each structure will need to be considered.\n",
    "\n",
    "Let's jump into implementing our handoff agents workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three key things that we need to use when defining our `main_agent` (equivalent to our earlier `orchestrator` agent), those are:\n",
    "\n",
    "* Update our `instructions` prompt to make it clear what the handoffs are and how they should be used. OpenAI provides a default _prompt prefix_ that we can use.\n",
    "* Set the `handoffs` parameter, which is a list of agents that we can use as handoffs.\n",
    "* Set the `handoff_description` parameter, this is an additional prompt where we should describe to the `main_agent` when it should use the `handoffs`.\n",
    "\n",
    "First, let's check the preset prompt prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# System context\n",
       "You are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "display(Markdown(RECOMMENDED_PROMPT_PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_agent, internal_docs_agent, code_execution_agent],\n",
    "    handoff_description=(\n",
    "        \"Handoff to the relevant agent for queries where we need additional information \"\n",
    "        \"from the web or internal docs, or when we need to make calculations.\"\n",
    "    ),\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the same queries as before and see how the response time differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The last revenue report we received was the Quarterly Revenue Report for Q1 2025, dated April 2, 2025. \n",
       "\n",
       "Since today is May 5, 2025, the last revenue report was about 1 month and 3 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's correct, we also got a `6.4s` runtime vs. the orchestrator-subagent runtime of `7.5s` for the same query. Let's try another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- The current revenue for Skynet Inc. in Q1 2025 is $6.9 billion.\n",
       "- Of this, approximately 16.67% of revenue comes from T-1000 Infiltration Units.\n",
       "\n",
       "If you need a breakdown or more details, let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=(\n",
    "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
    "        \"T-1000 units?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is correct again, and we get a runtime of `7.6s` vs. the orchestrator-subagent runtime of `8.6s`, another notable improvement to latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Handoff Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other handoff-specific features that we can use, these can be used for various things but are particularly useful during development and debugging of multi-agent workflows. These features are:\n",
    "\n",
    "* `on_handoff` is a callback executed whenever a handoff occurs. It could be used in a production setting to maintain a record of handoffs in a DB or used in telemetry. In development this can be a handy place to add `print` or `logger.debug` statements.\n",
    "* `input_type` allows us to define a specific structured input format for generated information that will be passed to our handoff agents.\n",
    "* `input_filter` allows us to restrict the information being passed through to our handoff agents.\n",
    "\n",
    "We can set all of these via a `handoff` object, which wraps around our handoff agents and which we then provide via the `Agent(handoffs=...)` parameter. Let's start with the `on_handoff` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import RunContextWrapper, handoff\n",
    "\n",
    "# we define a function that will be called when the handoff is made\n",
    "async def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff called\")\n",
    "\n",
    "# we then pass this function to the handoff object\n",
    "web_search_handoff = handoff(agent=web_search_agent, on_handoff=on_handoff)\n",
    "internal_docs_handoff = handoff(agent=internal_docs_agent, on_handoff=on_handoff)\n",
    "code_execution_handoff = handoff(agent=code_execution_agent, on_handoff=on_handoff)\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens when querying the `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff called\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report was for Q1 2025 and the report date is April 2, 2025. \n",
       "\n",
       "From today, May 5, 2025, the last revenue report was released 33 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see _if and when_ the handoff occurs. However, we don't get much information _other than_ that the handoff occured. Fortunately, we can use the `input_type` parameter to provide more information. We will define a pydantic `BaseModel` with the information that we'd like to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class HandoffInfo(BaseModel):\n",
    "    subagent_name: str = Field(description=\"The name of the subagent being called.\")\n",
    "    reason: str = Field(description=\"The reason for the handoff.\")\n",
    "\n",
    "# we redefine the on_handoff to include the HandoffInfo\n",
    "async def on_handoff(ctx: RunContextWrapper[None], input_data: HandoffInfo):\n",
    "    print(f\"Handoff to '{input_data.subagent_name}' because '{input_data.reason}'\")\n",
    "\n",
    "# now redefine the handoff objects with the input_type parameter\n",
    "web_search_handoff = handoff(\n",
    "    agent=web_search_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "internal_docs_handoff = handoff(\n",
    "    agent=internal_docs_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "code_execution_handoff = handoff(\n",
    "    agent=code_execution_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff to 'Internal Docs Agent' because 'The user is asking for the date of the last revenue report to calculate how long ago it was.'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report was for Q1 2025, dated April 2, 2025. \n",
       "\n",
       "Considering today is May 5, 2025, the last revenue report was about 33 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now seeing _much_ more information. The final handoff feature we will test is the `handoff_filters`. The filters work by removing information sent to the handoff agents. By default, all information seen by the previous agent will be seen by the new handoff agent. That includes all chat history message and all tool calls made so far.\n",
    "\n",
    "In some cases we may want to filter this information. For example, with a weaker LLM, too much information can reduce it's performance so it is often a good idea to only share the information that is absolutely necessary.\n",
    "\n",
    "If we have various tool calls in our chat history, these may confuse a smaller LLM. In this scenario, we can filter all tool calls from the history using the `handoff_filters.remove_all_tools` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions import handoff_filters\n",
    "\n",
    "# now redefine the handoff objects with the input_type parameter\n",
    "web_search_handoff = handoff(\n",
    "    agent=web_search_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "internal_docs_handoff = handoff(\n",
    "    agent=internal_docs_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "code_execution_handoff = handoff(\n",
    "    agent=code_execution_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when asking for the time difference we will see that our handoff agent is unable to give us an accurate answer. This is because the current time is first found by our `main_agent` via the `get_current_date` tool and that information is stored in the chat history. When we filter tool calls out of the chat history this information is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff to 'Internal Docs Agent' because 'To identify the date of the last revenue report in order to determine how long ago it was from today (2025-05-05).'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report we received was for Q1 2025, dated April 2, 2025. Today is April 27, 2025, so the report was received about 25 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see an incorrect date above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this deep dive into multi-agent systems with OpenAI's Agents SDK. We've covered a broad range of multi-agent features in the SDK and how we can use them to build **orchestrator-subagent** workflows, or **handoff** workflows. Both having their own pros and cons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
