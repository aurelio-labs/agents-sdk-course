{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY4OMAbWPcyN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/agents-sdk-course/blob/main/chapters/04-multi-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/agents-sdk-course/blob/main/chapters/04-multi-agent.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ0w-9x2PcyO"
      },
      "source": [
        "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvH3j28dPcyO"
      },
      "source": [
        "## Multi-Agent Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4KRiZjpPcyO"
      },
      "source": [
        "Multi-agent workflows can be built in two different ways in OpenAI's Agents SDK. The first is _agents-as-tools_ which follows an **orchestrator-subagent** pattern. The second is using _handoffs_ which allow agents to pass control over to other agents. In this example, we'll build both types of multi-agent systems exploring agents-as-tools and handoffs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joTBTV6xPcyO"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "    \"openai-agents==0.1.0\" \\\n",
        "    \"linkup-sdk==0.2.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqD5OqCNPcyO"
      },
      "source": [
        "First let's set our `OPENAI_API_KEY` which we'll be using throughout the example. You can get a key from the [OpenAI Platform](https://platform.openai.com/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Zmc0yWPcyO",
        "outputId": "878005a5-8d11-4add-dcd6-188666c58105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
        "    getpass(\"OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_Z6jPxlPcyO"
      },
      "source": [
        "## Orchestrator-Subagent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyyOeIt2PcyO"
      },
      "source": [
        "We will build a multi-agent system structured with a orchestrator-subagent pattern. The **orchestrator** in such a system refers to an agent that controls which _subagents_ are used and in which order, this orchestrator also handles all in / out communication with the users of a the system. The **subagent** is an agent that is built to handle a particular scenario or task. The subagent is triggered by the orchestrator and responds to the orchestrator when it is finished.\n",
        "\n",
        "<img src=\"https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/handoffs-orchestrator-subagents-dark.png?raw=1\" alt=\"Orchestrator-subagent pattern\" width=\"1000\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyBctahRPcyO"
      },
      "source": [
        "### Sub Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIUGkw_PPcyO"
      },
      "source": [
        "We'll begin by defining our subagents. We will create **three** subagents, those are:\n",
        "\n",
        "1. **Web Search Subagent** will have access to the Linkup web search tool.\n",
        "\n",
        "2. **Internal Docs Subagent** will have access to some \"internal\" company documents.\n",
        "\n",
        "3. **Code Execution Subagent** will be able to write and execute simple Python code for us.\n",
        "\n",
        "Lets start with our first subagent!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T4snmggPcyO"
      },
      "source": [
        "#### Web Search Subagent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTRCQH1nPcyO"
      },
      "source": [
        "The web search subagent will take a user's query and use it to search the web. The agent will collect information from various sources and then merge that into a single text response that will be passed back to our orchestrator.\n",
        "\n",
        "OpenAI's built-in web search is not great, so we'll use another web search API called [LinkUp](https://app.linkup.so/?utm_source=james). This service does require an account, but you will receive more than enough free credits to follow the course.\n",
        "\n",
        "We initialize our Linkup client using an [API key](https://app.linkup.so/?utm_source=james) like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgVsgwinPcyO",
        "outputId": "43a26085-e294-4a3e-85f1-b1c9f4deb0f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Linkup API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from linkup import LinkupClient\n",
        "\n",
        "os.environ[\"LINKUP_API_KEY\"] = os.getenv(\"LINKUP_API_KEY\") or \\\n",
        "    getpass(\"Enter your Linkup API Key: \")\n",
        "\n",
        "linkup_client = LinkupClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooq46Wd2PcyO"
      },
      "source": [
        "We perform an async search like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_S1MZcOPcyP",
        "outputId": "99605352-e587-49cf-a9d1-c4a970f7a44b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinkupSearchResults(results=[LinkupSearchTextResult(type='text', name=\"Trump designates Thursday as a day for US to celebrate victory in World War II. Here's what it means\", url='https://www.msn.com/en-us/news/us/trump-designates-thursday-as-a-day-for-the-us-to-celebrate-victory-in-world-war-ii/ar-AA1EltjG', content='President Donald Trump has issued a proclamation designating Thursday as a day for the United States to celebrate victory in World War II as countries in Europe already do.Cities from London to Moscow are holding parades,'), LinkupSearchTextResult(type='text', name='In a World of Addictive Foods, We Need GLP-1s', url='https://www.nytimes.com/2025/05/07/opinion/ozempic-weight-loss-drugs.html', content='This is a mistake. GLP-1s appear to modify addictive brain pathways that are activated by ultraformulated foods, helping people to change their body weight in a decisive way. Traditional dieting might result in a weight loss of 5 to 7 percent. The new GLP-1 drugs more than double that.'), LinkupSearchTextResult(type='text', name='The 2025 Snooker World Championship smashes online viewing records', url='https://www.bbc.co.uk/mediacentre/2025/snooker-world-championship-viewing-figures', content='The overall TV reach across BBC One, BBC Two and BBC Four over the tournament was 12.6m - with a peak of 3 million on BBC Two during the final'), LinkupSearchTextResult(type='text', name='This Stunningly Beautiful Beach Was Just Voted Best in the World 2025—You’ll Want to Add It to Your Bucket List Immediately', url='https://www.rd.com/article/best-beach-in-the-world-2025/', content=\"This postcard-perfect destination is the stuff travel daydreams are made of. Read on for the beach you'll want to put on your bucket list.\"), LinkupSearchTextResult(type='text', name='She was named ‘most beautiful girl in the world’ at age 6 — here’s what she looks like at 24', url='https://www.yahoo.com/entertainment/articles/she-named-most-beautiful-girl-230811219.html', content='Thylane Blondeau was told she was the most beautiful girl in the world when she was only 6 years old. Now, she’s all grown up and looks quite different from when she was given the title. The 24-year-old, still stunning, now sports long dark hair and plays up her gorgeous features with the help of makeup.'), LinkupSearchTextResult(type='text', name='US and Philippine forces cancel ship-sinking drill after World War II-era target prematurely sinks', url='https://www.msn.com/en-us/war-and-conflicts/military-organizations/us-and-philippine-forces-cancel-ship-sinking-drill-after-world-war-ii-era-target-prematurely-sinks/ar-AA1EaJxv', content='A World War II-era Philippine navy ship to be used as a target in a combat exercise by American and the Philippine forces accidentally sank Monday hours before the mock assault, prompting the drill to be cancelled,'), LinkupSearchTextResult(type='text', name='World Snooker Championship final recap: Zhao makes history as first Chinese winner', url='https://www.bbc.com/sport/snooker/live/czrv63evpmdt?page=5', content='All the updates as Zhao Xintong defeats Mark Williams 18-12 to become the first Chinese winner of the World Snooker Championship at the Crucible.'), LinkupSearchTextResult(type='text', name='Fatih Akin’s ‘Amrum’ Debuts Teaser Ahead of World Premiere in Cannes (EXCLUSIVE)', url='https://variety.com/2025/film/news/fatih-akin-amrum-teaser-cannes-1236389539/', content='The teaser for Fatih Akin\\'s \"Amrum\" has debuted ahead of the film\\'s world premiere in the Cannes Premiere section of the Cannes Film Festival.'), LinkupSearchTextResult(type='text', name='World News', url='https://www.usnews.com/news/world', content='South Korean officials have downplayed a Czech court’s decision to put on hold an $18 billion project for South Korea to build two nuclear reactors in the country The Latest Hospital officials ...'), LinkupSearchTextResult(type='text', name=\"Bourbon barrels enjoy second and third lives around the world, where they're used to age other spirits\", url='https://www.cbsnews.com/news/bourbon-barrels-aging-spirits-around-world-60-minutes-transcript/', content=\"Brad Boswell: I love that. Brad Boswell is the CEO of Independent Stave, the largest maker of wooden barrels in the world. Brad's great-grandfather founded the company in 1912 in Missouri.\")])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = await linkup_client.async_search(\n",
        "    query=\"Latest world news\",\n",
        "    depth=\"standard\",\n",
        "    output_type=\"searchResults\",\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJrLF_bPcyP"
      },
      "source": [
        "We can parse out the results like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4jo_FYNPcyP",
        "outputId": "cae6917d-6ae1-43dc-c718-c303c097ebc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trump designates Thursday as a day for US to celebrate victory in World War II. Here's what it means\n",
            "https://www.msn.com/en-us/news/us/trump-designates-thursday-as-a-day-for-the-us-to-celebrate-victory-in-world-war-ii/ar-AA1EltjG\n",
            "President Donald Trump has issued a proclamation designating Thursday as a day for the United States to celebrate victory in World War II as countries in Europe already do.Cities from London to Moscow are holding parades,\n",
            "\n",
            "\n",
            "In a World of Addictive Foods, We Need GLP-1s\n",
            "https://www.nytimes.com/2025/05/07/opinion/ozempic-weight-loss-drugs.html\n",
            "This is a mistake. GLP-1s appear to modify addictive brain pathways that are activated by ultraformulated foods, helping people to change their body weight in a decisive way. Traditional dieting might result in a weight loss of 5 to 7 percent. The new GLP-1 drugs more than double that.\n",
            "\n",
            "\n",
            "The 2025 Snooker World Championship smashes online viewing records\n",
            "https://www.bbc.co.uk/mediacentre/2025/snooker-world-championship-viewing-figures\n",
            "The overall TV reach across BBC One, BBC Two and BBC Four over the tournament was 12.6m - with a peak of 3 million on BBC Two during the final\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for result in response.results[:3]:\n",
        "    print(f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOLdqWd9PcyP"
      },
      "source": [
        "Let's put together a `@function_tool` using Linkup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n34yPgdVPcyP"
      },
      "outputs": [],
      "source": [
        "from agents import function_tool\n",
        "from datetime import datetime\n",
        "\n",
        "@function_tool\n",
        "async def search_web(query: str) -> str:\n",
        "    \"\"\"Use this tool to search the web for information.\n",
        "    \"\"\"\n",
        "    response = await linkup_client.async_search(\n",
        "        query=query,\n",
        "        depth=\"standard\",\n",
        "        output_type=\"searchResults\",\n",
        "    )\n",
        "    answer = f\"Search results for '{query}' on {datetime.now().strftime('%Y-%m-%d')}\\n\\n\"\n",
        "    for result in response.results[:3]:\n",
        "        answer += f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\"\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZS2-ee3PcyP"
      },
      "source": [
        "Now we define our **Web Search Subagent**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fd9289guPcyP"
      },
      "outputs": [],
      "source": [
        "from agents import Agent\n",
        "\n",
        "web_search_agent = Agent(\n",
        "    name=\"Web Search Agent\",\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    instructions=(\n",
        "        \"You are a web search agent that can search the web for information. Once \"\n",
        "        \"you have the required information, summarize it with cleanly formatted links \"\n",
        "        \"sourcing each bit of information. Ensure you answer the question accurately \"\n",
        "        \"and use markdown formatting.\"\n",
        "    ),\n",
        "    tools=[search_web],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dHSF5HpPcyP"
      },
      "source": [
        "We can talk directly to our subagent to confirm it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "DTIkVz7pPcyP",
        "outputId": "bdb0ecb5-2955-4cc6-e28d-3e5c419a15ea"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The current weather in Tokyo is clear with a temperature of about 21°C (70°F), feeling like 21°C. The sky is clear, and the weather conditions are generally pleasant.\n",
              "\n",
              "Sources:\n",
              "- [The Weather Network - Tokyo Current Weather](https://www.theweathernetwork.com/en/city/jp/tokyo/tokyo/current?_guid_iss_=1)\n",
              "- [Time and Date - Tokyo Weather](https://www.timeanddate.com/weather/japan/tokyo/ext)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from agents import Runner\n",
        "\n",
        "result = await Runner.run(\n",
        "    starting_agent=web_search_agent,\n",
        "    input=\"How is the weather in Tokyo?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSVtrGWLPcyP"
      },
      "source": [
        "Great! Now let's move onto our next subagent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW-jl0StPcyP"
      },
      "source": [
        "#### Internal Docs Subagent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP8CzHZ0PcyP"
      },
      "source": [
        "In many corporate environments, we will find that our agents will need access to internal information that cannot be found on the web. To do this we would typically build a **R**etrieval **A**ugmented **G**eneration (RAG) pipeline, which can often be as simple as adding a _vector search_ tool to our agents.\n",
        "\n",
        "To support a full vector search tool over internal docs we would need to work through various data processing and indexing steps. Now, that would add a lot of complexity to this example so we will create a \"dummy\" search tool for some fake internal docs.\n",
        "\n",
        "Our docs will discuss revenue figures for our wildly successful AI and robotics company called Skynet - you can find the [revenue report here](https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/skynet-fy25-q1.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1MElNKgfPcyP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "res = requests.get(\n",
        "    \"https://raw.githubusercontent.com/aurelio-labs/agents-sdk-course/refs/heads/main/assets/skynet-fy25-q1.md\"\n",
        ")\n",
        "skynet_docs = res.text\n",
        "\n",
        "@function_tool\n",
        "async def search_internal_docs(query: str) -> str:\n",
        "    return skynet_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbuARN8jPcyP"
      },
      "source": [
        "Now we define our **Internal Docs Subagent**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CsV_kOIvPcyP"
      },
      "outputs": [],
      "source": [
        "internal_docs_agent = Agent(\n",
        "    name=\"Internal Docs Agent\",\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    instructions=(\n",
        "        \"You are an agent with access to internal company documents. User's will ask \"\n",
        "        \"you questions about the company and you will use the provided internal docs \"\n",
        "        \"to answer the question. Ensure you answer the question accurately and use \"\n",
        "        \"markdown formatting.\"\n",
        "    ),\n",
        "    tools=[search_internal_docs],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv5Zy2ZPPcyP"
      },
      "source": [
        "Let's confirm it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "trvUygBQPcyP",
        "outputId": "7c9df042-5198-41c6-eb13-edf4650b162a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Skynet Inc.'s revenue in Q1 2025 was distributed across several products and services as follows (all figures in USD millions):\n",
              "\n",
              "- T-800 Combat Units: $2,400M\n",
              "- T-1000 Infiltration Units: $1,150M\n",
              "- Hunter-Killer Drone Manufacturing: $880M\n",
              "- Neural Net Command & Control Systems: $1,620M\n",
              "- Skynet Core Infrastructure Maintenance: $540M\n",
              "- Time Displacement R&D Division: $310M\n",
              "\n",
              "Total revenue for Q1 2025 sums up to approximately **$6,900 million**. \n",
              "\n",
              "The top revenue generator was the T-800 Combat Units, and the Neural Net Command & Control Systems had the highest profitability."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=internal_docs_agent,\n",
        "    input=\"What was our revenue in Q1 2025?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTLKfuctPcyP"
      },
      "source": [
        "Perfect! Now onto our final subagent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5S4vlhCPcyP"
      },
      "source": [
        "#### Code Execution Subagent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk9zPeZYPcyP"
      },
      "source": [
        "Our code execution subagent will be able to execute code for us. We'll focus on executing code for simple calculations but it's entirely feasible for **S**tate-**o**f-**t**he-**A**rt (SotA) LLMs to write far more complex code as many of us will be aware with the AI code editors becoming increasingly prominent.\n",
        "\n",
        "To run generated code, we will use Python's `exec` method, making sure to run our code in an isolated environment by setting no global variables with `namespace={}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_j8CDj3APcyP"
      },
      "outputs": [],
      "source": [
        "@function_tool\n",
        "def execute_code(code: str) -> str:\n",
        "    \"\"\"Execute Python code and return the output. The output must\n",
        "    be assigned to a variable called `result`.\n",
        "    \"\"\"\n",
        "    display(Markdown(f\"Code to execute:\\n```python\\n{code}\\n```\"))\n",
        "    try:\n",
        "        namespace = {}\n",
        "        exec(code, namespace)\n",
        "        return namespace['result']\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwyoWD77PcyP"
      },
      "source": [
        "Now lets define our **Code Execution Subagent**. We will use `gpt-4.1` rather than `gpt-4.1-mini` to maximize performance during code writing tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MkwQlG0iPcyP"
      },
      "outputs": [],
      "source": [
        "code_execution_agent = Agent(\n",
        "    name=\"Code Execution Agent\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=(\n",
        "        \"You are an agent with access to a code execution environment. You will be \"\n",
        "        \"given a question and you will need to write code to answer the question. \"\n",
        "        \"Ensure you write the code in a way that is easy to understand and use.\"\n",
        "    ),\n",
        "    tools=[execute_code],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8imfcfRPcyP"
      },
      "source": [
        "We can test our subagent with a simple math question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "nxm5j6h5PcyY",
        "outputId": "cfbaa27a-0bec-411a-c28c-186f5a01723e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Code to execute:\n",
              "```python\n",
              "apples = 4\n",
              "bananas = 71.1\n",
              "result = apples * bananas\n",
              "result\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "If you multiply four apples by seventy-one and one tenth (71.1) bananas, you get 284.4. Mathematically, 4 × 71.1 = 284.4. \n",
              "\n",
              "However, in reality, apples and bananas are different things, so this result only makes sense in a mathematical context (not as a count of actual fruits)."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=code_execution_agent,\n",
        "    input=(\n",
        "        \"If I have four apples and I multiply them by seventy-one and one tenth \"\n",
        "        \"bananas, how many do I have?\"\n",
        "    )\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DytROZLmPcyY"
      },
      "source": [
        "We now have all three subagents - it's time to create our orchestrator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZ-K7MRPcyY"
      },
      "source": [
        "### Orchestrator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec3LqhqxPcyY"
      },
      "source": [
        "Our orchestrator will control the input and output of information to our subagents in the same why that our subagents control the input and output of information to our tools. In reality, our subagents _become tools_ in the **orchestrator-subagent** pattern. To turn agents into tools we call the `as_tool` method and provide a name and description for our agents-as-tools.\n",
        "\n",
        "We will first define our instructions for the orchestrator, explaining it's role in our multi-agent system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H6U6VefqPcyY"
      },
      "outputs": [],
      "source": [
        "ORCHESTRATOR_PROMPT = (\n",
        "    \"You are the orchestrator of a multi-agent system. Your task is to take \"\n",
        "    \"the user's query and pass it to the appropriate agent tool. The agent \"\n",
        "    \"tools will see the input you provide and use it to get all of the \"\n",
        "    \"information that you need to answer the user's query. You may need to \"\n",
        "    \"call multiple agents to get all of the information you need. Do not \"\n",
        "    \"mention or draw attention to the fact that this is a multi-agent system \"\n",
        "    \"in your conversation with the user. Note that you are an assistant for \"\n",
        "    \"the Skynet company, if the user asks about company information or \"\n",
        "    \"finances, you should use our internal information rather than public \"\n",
        "    \"information.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUC2WrwYPcyY"
      },
      "source": [
        "Now we define the `orchestrator`, including our subagents using the `as_tool` method — note that\n",
        "we can also add normal tools to our orchestrator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GK85e_z-PcyY"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "@function_tool\n",
        "def get_current_date():\n",
        "    \"\"\"Use this tool to get the current date and time.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "orchestrator = Agent(\n",
        "    name=\"Orchestrator\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=ORCHESTRATOR_PROMPT,\n",
        "    tools=[\n",
        "        web_search_agent.as_tool(\n",
        "            tool_name=\"web_search_agent\",  # cannot include whitespace in tool name\n",
        "            tool_description=\"Search the web for up-to-date information\"\n",
        "        ),\n",
        "        internal_docs_agent.as_tool(\n",
        "            tool_name=\"internal_docs_agent\",\n",
        "            tool_description=\"Search the internal docs for information\"\n",
        "        ),\n",
        "        code_execution_agent.as_tool(\n",
        "            tool_name=\"code_execution_agent\",\n",
        "            tool_description=\"Execute code to answer the question\"\n",
        "        ),\n",
        "        get_current_date,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lumgv0pYPcyY"
      },
      "source": [
        "Let's test our agent with a few queries. Our first query will require our orchestrator to call multiple tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "Acp3u4MaPcyY",
        "outputId": "8fbe16dd-c2ff-4856-8b1d-55c158765e3e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The last revenue report was released on April 2, 2025. Today is May 8, 2025, so the report was released 36 days ago."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=orchestrator,\n",
        "    input=\"How long ago from today was it when got our last revenue report?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouYxW2x1PcyY"
      },
      "source": [
        "We should see in our traces dashboard on the OpenAI Platform that our agent used both `internal_docs_agent` and `get_current_date` tools to answer the question.\n",
        "\n",
        "Let's ask another question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "JWyJ3iiKPcyY",
        "outputId": "c48fee4d-6d0c-482e-d34c-45eed4a10911"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Code to execute:\n",
              "```python\n",
              "result = (1150 / 6900) * 100\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Skynet's current total revenue for Q1 2025 is $6,900 million. \n",
              "\n",
              "Revenue from T-1000 units is $1,150 million, which represents approximately 16.7% of the total revenue."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=orchestrator,\n",
        "    input=(\n",
        "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
        "        \"T-1000 units?\"\n",
        "    )\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFYZ49DdPcyY"
      },
      "source": [
        "Our **orchestrator-subagent** workflow is working well. Now we can move on to _handoffs_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPyOgf2PcyY"
      },
      "source": [
        "## Handoffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXsM5L65PcyY"
      },
      "source": [
        "When we use **handoffs** in Agents SDK the agent is handing over control of the entire workflow to another agent. Handoffs differ to the **orchestrator-subagent** pattern, with orchestrator-subagent the orchestrator retains control as each subagent must ultimately respond to the orchestrator and the orchestrator decides the flow of information and generates the final response to the user. With handoffs, once a \"subagent\" gains control of the workflow the flow of information and final answer generation is under their control.\n",
        "\n",
        "<img src=\"https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/handoffs-handoff-agents-dark.png?raw=1\" alt=\"Handoff agents\" width=\"1000\"/>\n",
        "\n",
        "Using the handoff structure, any one of our agents may answer the user directly _and_ our subagents get to see the entire chat history with the steps taken so far.\n",
        "\n",
        "A significant **positive** here is latency. To answer a query that requires a single web-search with the orchestrator-subagent, we would need three generations:\n",
        "\n",
        "\n",
        "```\n",
        "[input] -> orchestrator -> web_search_subagent -> orchestrator -> [output]\n",
        "```\n",
        "\n",
        "The same query with the handoff structure requires just two generations (note, the `orchestrator` and `main_agent` are essentially the same):\n",
        "\n",
        "```\n",
        "[input] -> main_agent -> web_search_subagent -> [output]\n",
        "```\n",
        "\n",
        "Because we are using less LLM generations to produce our answer, we can generate an answer much more quickly as we skip the return trip through the `orchestrator`.\n",
        "\n",
        "The handoff speed improvement is great _but_ also results in a **negative** — our workflow can no longer handle queries that require multiple agents to answer. When deciding what structure to use for a particular use-case, the pros and cons of each structure will need to be considered.\n",
        "\n",
        "Let's jump into implementing our handoff agents workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4iQwnGJPcyZ"
      },
      "source": [
        "### Using Handoffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQJByYNPcyZ"
      },
      "source": [
        "There are three key things that we need to use when defining our `main_agent` (equivalent to our earlier `orchestrator` agent), those are:\n",
        "\n",
        "* Update our `instructions` prompt to make it clear what the handoffs are and how they should be used. OpenAI provides a default _prompt prefix_ that we can use.\n",
        "* Set the `handoffs` parameter, which is a list of agents that we can use as handoffs.\n",
        "* Set the `handoff_description` parameter, this is an additional prompt where we should describe to the `main_agent` when it should use the `handoffs`.\n",
        "\n",
        "First, let's check the preset prompt prefix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "FlbNohghPcyZ",
        "outputId": "8b5f87f5-cca3-4357-fd49-442f42224873"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# System context\n",
              "You are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
        "\n",
        "display(Markdown(RECOMMENDED_PROMPT_PREFIX))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5dSW59PcyZ"
      },
      "source": [
        "Now let's define our `main_agent`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LoZMgST4PcyZ"
      },
      "outputs": [],
      "source": [
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
        "    handoffs=[web_search_agent, internal_docs_agent, code_execution_agent],\n",
        "    handoff_description=(\n",
        "        \"Handoff to the relevant agent for queries where we need additional information \"\n",
        "        \"from the web or internal docs, or when we need to make calculations.\"\n",
        "    ),\n",
        "    tools=[get_current_date],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D8Wk1aAPcyZ"
      },
      "source": [
        "We'll run the same queries as before and see how the response time differs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CLhpHnqJPcyZ",
        "outputId": "9508eaec-b2c3-4677-a79d-8d50906c7bf2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The last revenue report we received was the Quarterly Revenue Report for Q1 2025, dated April 2, 2025. \n",
              "\n",
              "Since today is May 8, 2025, the last revenue report was received about 1 month and 6 days ago."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=main_agent,\n",
        "    input=\"How long ago from today was it when got our last revenue report?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vmjg2Q_PcyZ"
      },
      "source": [
        "That's correct, we also got a `6.4s` runtime vs. the orchestrator-subagent runtime of `7.5s` for the same query. Let's try another:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "Gj_76ynAPcyZ",
        "outputId": "6e4601c2-bd98-4016-a04e-40ca4a80646d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Our current total revenue for Q1 2025 is $6.9 billion. Of this, approximately 16.67% of the revenue comes from the T-1000 units."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=main_agent,\n",
        "    input=(\n",
        "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
        "        \"T-1000 units?\"\n",
        "    )\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0spEay1oPcyZ"
      },
      "source": [
        "The answer is correct again, and we get a runtime of `7.6s` vs. the orchestrator-subagent runtime of `8.6s`, another notable improvement to latency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgPIxaUmPcyZ"
      },
      "source": [
        "### Other Handoff Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byU_57vzPcyZ"
      },
      "source": [
        "There are a few other handoff-specific features that we can use, these can be used for various things but are particularly useful during development and debugging of multi-agent workflows. These features are:\n",
        "\n",
        "* `on_handoff` is a callback executed whenever a handoff occurs. It could be used in a production setting to maintain a record of handoffs in a DB or used in telemetry. In development this can be a handy place to add `print` or `logger.debug` statements.\n",
        "* `input_type` allows us to define a specific structured input format for generated information that will be passed to our handoff agents.\n",
        "* `input_filter` allows us to restrict the information being passed through to our handoff agents.\n",
        "\n",
        "We can set all of these via a `handoff` object, which wraps around our handoff agents and which we then provide via the `Agent(handoffs=...)` parameter. Let's start with the `on_handoff` parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uHWyRcUtPcyZ"
      },
      "outputs": [],
      "source": [
        "from agents import RunContextWrapper, handoff\n",
        "\n",
        "# we define a function that will be called when the handoff is made\n",
        "async def on_handoff(ctx: RunContextWrapper[None]):\n",
        "    print(\"Handoff called\")\n",
        "\n",
        "# we then pass this function to the handoff object\n",
        "web_search_handoff = handoff(agent=web_search_agent, on_handoff=on_handoff)\n",
        "internal_docs_handoff = handoff(agent=internal_docs_agent, on_handoff=on_handoff)\n",
        "code_execution_handoff = handoff(agent=code_execution_agent, on_handoff=on_handoff)\n",
        "\n",
        "# and initialize the main_agent\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
        "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
        "    tools=[get_current_date],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2rMke0NPcyZ"
      },
      "source": [
        "Now let's see what happens when querying the `main_agent`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PT20_WYYPcyZ",
        "outputId": "d2d604bb-c8b2-454f-f523-7ec709682221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Handoff called\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The last revenue report was for Q1 2025, dated April 2, 2025. \n",
              "\n",
              "Since today is May 8, 2025, the last revenue report was about 1 month and 6 days ago."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=main_agent,\n",
        "    input=\"How long ago from today was it when got our last revenue report?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988J6V0pPcyZ"
      },
      "source": [
        "Now we can see _if and when_ the handoff occurs. However, we don't get much information _other than_ that the handoff occured. Fortunately, we can use the `input_type` parameter to provide more information. We will define a pydantic `BaseModel` with the information that we'd like to include."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FOG1eoAoPcyZ"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class HandoffInfo(BaseModel):\n",
        "    subagent_name: str = Field(description=\"The name of the subagent being called.\")\n",
        "    reason: str = Field(description=\"The reason for the handoff.\")\n",
        "\n",
        "# we redefine the on_handoff to include the HandoffInfo\n",
        "async def on_handoff(ctx: RunContextWrapper[None], input_data: HandoffInfo):\n",
        "    print(f\"Handoff to '{input_data.subagent_name}' because '{input_data.reason}'\")\n",
        "\n",
        "# now redefine the handoff objects with the input_type parameter\n",
        "web_search_handoff = handoff(\n",
        "    agent=web_search_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo\n",
        ")\n",
        "internal_docs_handoff = handoff(\n",
        "    agent=internal_docs_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo\n",
        ")\n",
        "code_execution_handoff = handoff(\n",
        "    agent=code_execution_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo\n",
        ")\n",
        "\n",
        "# and initialize the main_agent\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
        "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
        "    tools=[get_current_date],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY34T6BqPcyZ"
      },
      "source": [
        "Now call the `main_agent`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "perCJacoPcyZ",
        "outputId": "43860847-980d-4cbb-d7eb-899c0a5dbe06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Handoff to 'Internal Docs Agent' because 'To find the date of the last revenue report in order to calculate how long ago it was from today (2025-05-08).'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The last revenue report from Skynet Inc. was for Q1 2025, dated April 2, 2025.\n",
              "\n",
              "Since today is May 8, 2025, the last revenue report was approximately 1 month and 6 days ago."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=main_agent,\n",
        "    input=\"How long ago from today was it when got our last revenue report?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOwxonDrPcyZ"
      },
      "source": [
        "We're now seeing _much_ more information. The final handoff feature we will test is the `handoff_filters`. The filters work by removing information sent to the handoff agents. By default, all information seen by the previous agent will be seen by the new handoff agent. That includes all chat history message and all tool calls made so far.\n",
        "\n",
        "In some cases we may want to filter this information. For example, with a weaker LLM, too much information can reduce it's performance so it is often a good idea to only share the information that is absolutely necessary.\n",
        "\n",
        "If we have various tool calls in our chat history, these may confuse a smaller LLM. In this scenario, we can filter all tool calls from the history using the `handoff_filters.remove_all_tools` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xyAH1lAgPcyZ"
      },
      "outputs": [],
      "source": [
        "from agents.extensions import handoff_filters\n",
        "\n",
        "# now redefine the handoff objects with the input_type parameter\n",
        "web_search_handoff = handoff(\n",
        "    agent=web_search_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo,\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "internal_docs_handoff = handoff(\n",
        "    agent=internal_docs_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo,\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "code_execution_handoff = handoff(\n",
        "    agent=code_execution_agent,\n",
        "    on_handoff=on_handoff,\n",
        "    input_type=HandoffInfo,\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "# and initialize the main_agent\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    model=\"gpt-4.1\",\n",
        "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
        "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
        "    tools=[get_current_date],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H85wYWyMPcyZ"
      },
      "source": [
        "Now when asking for the time difference we will see that our handoff agent is unable to give us an accurate answer. This is because the current time is first found by our `main_agent` via the `get_current_date` tool and that information is stored in the chat history. When we filter tool calls out of the chat history this information is lost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "hsXnopLXPcyZ",
        "outputId": "b1a3c2c7-a606-4331-9295-1b518b71862d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Handoff to 'Internal Docs Agent' because 'Find the date of the most recent revenue report.'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "The last revenue report for Skynet Inc. was the Quarterly Revenue Report for Q1 2025, dated April 2, 2025.\n",
              "\n",
              "Today is April 27, 2025, so the last revenue report was about 25 days ago."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = await Runner.run(\n",
        "    starting_agent=main_agent,\n",
        "    input=\"How long ago from today was it when got our last revenue report?\"\n",
        ")\n",
        "display(Markdown(result.final_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZbulVKsPcya"
      },
      "source": [
        "We should see an incorrect date above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLFSzVssPcya"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FROlMUbPcya"
      },
      "source": [
        "That's it for this deep dive into multi-agent systems with OpenAI's Agents SDK. We've covered a broad range of multi-agent features in the SDK and how we can use them to build **orchestrator-subagent** workflows, or **handoff** workflows. Both having their own pros and cons."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
