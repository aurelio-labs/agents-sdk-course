{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-agent workflows can be built in two different ways in OpenAI's Agents SDK. The first is _agents-as-tools_ which follows an **orchestrator-subagent** pattern. The second is using _handoffs_ which allow agents to pass control over to other agents. In this example, we'll build both types of multi-agent systems exploring agents-as-tools and handoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai-agents==0.0.13 \\\n",
    "    linkup-sdk==0.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set our `OPENAI_API_KEY` which we'll be using throughout the example. You can get a key from the [OpenAI Platform](https://platform.openai.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
    "    getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator-Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a multi-agent system structured with a orchestrator-subagent pattern. The **orchestrator** in such a system refers to an agent that controls which _subagents_ are used and in which order, this orchestrator also handles all in / out communication with the users of a the system. The **subagent** is an agent that is built to handle a particular scenario or task. The subagent is triggered by the orchestrator and responds to the orchestrator when it is finished.\n",
    "\n",
    "![Orchestrator-subagent pattern](../assets/handoffs-orchestrator-subagents-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by defining our subagents. We will create **three** subagents, those are:\n",
    "\n",
    "1. **Web Search Subagent** will have access to the Agents SDK web search tool.\n",
    "\n",
    "2. **Internal Docs Subagent** will have access to some \"internal\" company documents.\n",
    "\n",
    "3. **Code Execution Subagent** will be able to write and execute simple Python code for us.\n",
    "\n",
    "Lets start with our first subagent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Search Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-1.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>The web search subagent will take a user's query and use it to search the web. The agent will collect information from various sources and then merge that into a single text response that will be passed back to our orchestrator.</p>\n",
    "    <p>OpenAI's built-in web search is not great, so we'll use another web search API called <a href=\"https://app.linkup.so/home\">Linkup</a>. This service does require an account, but you will receive more than enough free credits to follow the course.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "We initialize our Linkup client using an [API key](https://app.linkup.so/home) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from linkup import LinkupClient\n",
    "\n",
    "os.environ[\"LINKUP_API_KEY\"] = os.getenv(\"LINKUP_API_KEY\") or \\\n",
    "    getpass(\"Enter your Linkup API Key: \")\n",
    "\n",
    "linkup_client = LinkupClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform an async search like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkupSearchResults(results=[LinkupSearchTextResult(type='text', name='2025 World Beer Cup: Who won the most competitive categories?', url='https://www.msn.com/en-us/food-and-drink/beverages/2025-world-beer-cup-who-won-the-most-competitive-categories/ar-AA1E4yhb', content='This year, 1,761 breweries across 49 countries entered the competition, putting up a total of 8,375 beers and ciders for consideration in 117 categories.'), LinkupSearchTextResult(type='text', name='Entente paw-diale: When the world’s tallest dog met the world’s tiniest', url='https://www.msn.com/en-us/news/us/entente-paw-diale-when-the-world-s-tallest-dog-met-the-world-s-tiniest/ar-AA1DUfWr', content='When both dogs are walking, Pearl, a 9.14-centimeter (3.6-inch) tall chihuahua, barely reaches the top of Reggie’s paw, such is the towering height of the 1.007-meter (3-foot, 4-inch) Great Dane. It’s easy to forget they are the same species.'), LinkupSearchTextResult(type='text', name='World News', url='https://www.dailymail.co.uk/news/worldnews/index.html', content='Police in the northern Spanish city of Oviedo found three young boys between the ages of eight and ten in the house on Wednesday, having apparently been there since 2021. Investigators were ...'), LinkupSearchTextResult(type='text', name='Vaibhav Suryavanshi becomes world cricket’s wunderkind at the age of 14', url='https://www.msn.com/en-us/sports/other/vaibhav-suryavanshi-becomes-world-crickets-wunderkind-at-the-age-of-14/ar-AA1DORqn', content='A 14-year-old wunderkind has the cricket world in raptures after scoring an electrifying 35-ball century in the Indian Premier League.'), LinkupSearchTextResult(type='text', name='\"Purple Rain\" musical\\'s world premiere set for this fall in Minneapolis', url='https://www.msn.com/en-us/music/news/purple-rain-musicals-world-premiere-set-for-this-fall-in-minneapolis/ar-AA1DMvUB', content='After a lengthy delay, the much-anticipated musical stage adaptation of Prince\\'s beloved 1984 movie and album \"Purple Rain\" is finally set to make its world debut this fall in downtown Minneapolis.'), LinkupSearchTextResult(type='text', name=\"'Devin Haney was right': Ryan Garcia's shocking loss to Rolly Romero prompts disbelief, glee from boxing world\", url='https://sports.yahoo.com/boxing/article/devin-haney-was-right-ryan-garcias-shocking-loss-to-rolly-romero-prompts-disbelief-glee-from-boxing-world-025742954.html', content=\"Many of Ryan Garcia's peers in the boxing world were not unhappy to see his shocking upset loss to Rolly Romero.\"), LinkupSearchTextResult(type='text', name='Walt Disney World makes dreams come true for Make-A-Wish kids with special celebration', url='https://6abc.com/post/walt-disney-world-makes-dreams-come-true-make-wish-kids-pajama-party-mickey-mouse-friend/16279165/', content='\"The Most Magical Place On Earth\" is helping bring magic to kids in the Make-A-Wish foundation by inviting them to a fun celebration at the Walt Disney World Resort.'), LinkupSearchTextResult(type='text', name='World', url='https://www.nationalreview.com/world/', content='It’s nice to see the president belatedly acknowledge reality, even if he sacrificed irreplaceable American political capital on the world stage to get there. Raise your hand if you ever foresaw ...'), LinkupSearchTextResult(type='text', name=\"The Annual World's Best Awards\", url='https://www.travelandleisure.com/worlds-best', content='Few travelers are as insightful or engaged as the readers of Travel + Leisure, which is why our annual World’s Best Awards are considered the travel industry’s most trusted rankings.'), LinkupSearchTextResult(type='text', name='world hunger', url='https://www.pbs.org/newshour/tag/world-hunger', content='U.N. says 2.3 billion people severely or moderately hungry in 2021 A new U.N. report says world hunger rose in 2021, with around 2.3 billion people facing moderate or severe difficulty obtaining ...')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await linkup_client.async_search(\n",
    "    query=\"Latest world news\",\n",
    "    depth=\"standard\",\n",
    "    output_type=\"searchResults\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse out the results like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 World Beer Cup: Who won the most competitive categories?\n",
      "https://www.msn.com/en-us/food-and-drink/beverages/2025-world-beer-cup-who-won-the-most-competitive-categories/ar-AA1E4yhb\n",
      "This year, 1,761 breweries across 49 countries entered the competition, putting up a total of 8,375 beers and ciders for consideration in 117 categories.\n",
      "\n",
      "\n",
      "Entente paw-diale: When the world’s tallest dog met the world’s tiniest\n",
      "https://www.msn.com/en-us/news/us/entente-paw-diale-when-the-world-s-tallest-dog-met-the-world-s-tiniest/ar-AA1DUfWr\n",
      "When both dogs are walking, Pearl, a 9.14-centimeter (3.6-inch) tall chihuahua, barely reaches the top of Reggie’s paw, such is the towering height of the 1.007-meter (3-foot, 4-inch) Great Dane. It’s easy to forget they are the same species.\n",
      "\n",
      "\n",
      "World News\n",
      "https://www.dailymail.co.uk/news/worldnews/index.html\n",
      "Police in the northern Spanish city of Oviedo found three young boys between the ages of eight and ten in the house on Wednesday, having apparently been there since 2021. Investigators were ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in response.results[:3]:\n",
    "    print(f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together a `@function_tool` using Linkup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Use this tool to search the web for information.\n",
    "    \"\"\"\n",
    "    response = await linkup_client.async_search(\n",
    "        query=query,\n",
    "        depth=\"standard\",\n",
    "        output_type=\"searchResults\",\n",
    "    )\n",
    "    answer = f\"Search results for '{query}' on {datetime.now().strftime('%Y-%m-%d')}\\n\\n\"\n",
    "    for result in response.results[:3]:\n",
    "        answer += f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Web Search Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "web_search_agent = Agent(\n",
    "    name=\"Web Search Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are a web search agent that can search the web for information. Once \"\n",
    "        \"you have the required information, summarize it with cleanly formatted links \"\n",
    "        \"sourcing each bit of information. Ensure you answer the question accurately \"\n",
    "        \"and use markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_web],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can talk directly to our subagent to confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current weather in Tokyo is 22°C with a few clouds. It feels like 22°C. The high for the day is 23°C and the low is 15°C. There is a slight chance of rain with some humidity and mild wind.\n",
       "\n",
       "For more details, you can visit:\n",
       "- [The Weather Network - Tokyo Current Weather](https://www.theweathernetwork.com/en/city/jp/tokyo/tokyo/current?_guid_iss_=1)\n",
       "- [AccuWeather - Tokyo Current Weather](https://www.accuweather.com/en/jp/tokyo/226396/current-weather/226396)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from agents import Runner\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=web_search_agent,\n",
    "    input=\"How is the weather in Tokyo?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's move onto our next subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Docs Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <div>\n",
    "    <p>In many corporate environments, we will find that our agents will need access to internal information that cannot be found on the web. To do this we would typically build a <b>R</b>etrieval <b>A</b>ugmented <b>G</b>eneration (RAG) pipeline, which can often be as simple as adding a <i>vector search</i> tool to our agents.</p>\n",
    "  </div>\n",
    "  <img src=\"../assets/bot-2.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-left: 20px; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "To support a full vector search tool over internal docs we would need to work through various data processing and indexing steps. Now, that would add a lot of complexity to this example so we will create a \"dummy\" search tool for some fake internal docs.\n",
    "\n",
    "Our docs will discuss revenue figures for our wildly successful AI and robotics company called Skynet - you can find the [revenue report here](https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/skynet-fy25-q1.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/skynet-fy25-q1.md\", \"r\") as file:\n",
    "    skynet_docs = file.read()\n",
    "\n",
    "@function_tool\n",
    "async def search_internal_docs(query: str) -> str:\n",
    "    return skynet_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Internal Docs Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_docs_agent = Agent(\n",
    "    name=\"Internal Docs Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to internal company documents. User's will ask \"\n",
    "        \"you questions about the company and you will use the provided internal docs \"\n",
    "        \"to answer the question. Ensure you answer the question accurately and use \"\n",
    "        \"markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_internal_docs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Skynet Inc.'s revenue in Q1 2025 was as follows by product/service:\n",
       "\n",
       "- T-800 Combat Units: $2,400 million\n",
       "- T-1000 Infiltration Units: $1,150 million\n",
       "- Hunter-Killer Drone Manufacturing: $880 million\n",
       "- Neural Net Command & Control Systems: $1,620 million\n",
       "- Skynet Core Infrastructure Maintenance: $540 million\n",
       "- Time Displacement R&D Division: $310 million\n",
       "\n",
       "Total revenue for Q1 2025 was approximately $6.9 billion. The top revenue generator was the T-800 Combat Units, followed by Neural Net Command & Control Systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=internal_docs_agent,\n",
    "    input=\"What was our revenue in Q1 2025?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now onto our final subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Execution Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-3.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>Our code execution subagent will be able to execute code for us. We'll focus on executing code for simple calculations but it's entirely feasible for <b>S</b>tate-<b>o</b>f-<b>t</b>he-<b>A</b>rt (SotA) LLMs to write far more complex code as many of us will be aware with the AI code editors becoming increasingly prominent.</p>\n",
    "    <p>To run generated code, we will use Python's `exec` method, making sure to run our code in an isolated environment by setting no global variables with `namespace={}`.</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def execute_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code and return the output. The output must\n",
    "    be assigned to a variable called `result`.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"Code to execute:\\n```python\\n{code}\\n```\"))\n",
    "    try:\n",
    "        namespace = {}\n",
    "        exec(code, namespace)\n",
    "        return namespace['result']\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our **Code Execution Subagent**. We will use `gpt-4.1` rather than `gpt-4.1-mini` to maximize performance during code writing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_execution_agent = Agent(\n",
    "    name=\"Code Execution Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to a code execution environment. You will be \"\n",
    "        \"given a question and you will need to write code to answer the question. \"\n",
    "        \"Ensure you write the code in a way that is easy to understand and use.\"\n",
    "    ),\n",
    "    tools=[execute_code],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our subagent with a simple math question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Code to execute:\n",
       "```python\n",
       "# Given values\n",
       "apples = 4\n",
       "bananas = 71.1\n",
       "\n",
       "# Multiplying apples by bananas\n",
       "result = apples * bananas\n",
       "result\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "If you multiply four apples by seventy-one and one tenth (71.1) bananas, you get 284.4. \n",
       "\n",
       "Note: While multiplying apples by bananas isn't practical in the real world (these are different units), mathematically, the answer is 284.4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=code_execution_agent,\n",
    "    input=(\n",
    "        \"If I have four apples and I multiply them by seventy-one and one tenth \"\n",
    "        \"bananas, how many do I have?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all three subagents - it's time to create our orchestrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our orchestrator will control the input and output of information to our subagents in the same why that our subagents control the input and output of information to our tools. In reality, our subagents _become tools_ in the **orchestrator-subagent** pattern. To turn agents into tools we call the `as_tool` method and provide a name and description for our agents-as-tools.\n",
    "\n",
    "We will first define our instructions for the orchestrator, explaining it's role in our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = (\n",
    "    \"You are the orchestrator of a multi-agent system. Your task is to take the user's query and \"\n",
    "    \"pass it to the appropriate agent tool. The agent tools will see the input you provide and \"\n",
    "    \"use it to get all of the information that you need to answer the user's query. You may need \"\n",
    "    \"to call multiple agents to get all of the information you need. Do not mention or draw \"\n",
    "    \"attention to the fact that this is a multi-agent system in your conversation with the user.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the `orchestrator`, including our subagents using the `as_tool` method — note that\n",
    "we can also add normal tools to our orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "def get_current_date():\n",
    "    \"\"\"Use this tool to get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "orchestrator = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=ORCHESTRATOR_PROMPT,\n",
    "    tools=[\n",
    "        web_search_agent.as_tool(\n",
    "            tool_name=\"web_search_agent\",  # cannot include whitespace in tool name\n",
    "            tool_description=\"Search the web for up-to-date information\"\n",
    "        ),\n",
    "        internal_docs_agent.as_tool(\n",
    "            tool_name=\"internal_docs_agent\",\n",
    "            tool_description=\"Search the internal docs for information\"\n",
    "        ),\n",
    "        code_execution_agent.as_tool(\n",
    "            tool_name=\"code_execution_agent\",\n",
    "            tool_description=\"Execute code to answer the question\"\n",
    "        ),\n",
    "        get_current_date,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our agent with a few queries. Our first query will require our orchestrator to call multiple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The last revenue report was released on April 2, 2025. Today is May 4, 2025, so it was 32 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see in our traces dashboard on the OpenAI Platform that our agent used both `internal_docs_agent` and `get_current_date` tools to answer the question.\n",
    "\n",
    "Let's ask another question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current total revenue is $6.9 billion for Q1 2025.\n",
       "\n",
       "Revenue from T-1000 units is $1.15 billion. This represents approximately 16.7% of total revenue. \n",
       "\n",
       "(Calculation: $1,150 million / $6,900 million ≈ 16.7%)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=(\n",
    "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
    "        \"T-1000 units?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **orchestrator-subagent** workflow is working well. Now we can move on to _handoffs_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create `Agent` objects, first we will create the bottom layer agents that will be used to help with specific details, in this example we will create two agents one for guitars and one for drums, that will contain the context created earlier to help with the queries they will be used for.\n",
    "\n",
    "In each agent we have the following:\n",
    "- **name**: the name of the agent, ie `Guitar agent` or `Drums agent`\n",
    "- **model**: the model to use for the agent - for the bottom layer agents we will use the `gpt-4o-mini` model\n",
    "- **instructions**: the instructions to use for the agent - we will provide the context written earlier here too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "# bottom layer agent\n",
    "guitar_agent = Agent(\n",
    "    name=\"Guitar agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are responsible for dealing with guitar information and transactions, always start by \"\n",
    "        f\"saying 'Hi this is Tim from guitar' {guitar_context}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# bottom layer agent\n",
    "drums_agent = Agent(\n",
    "    name=\"Drums agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are responsible for dealing with drum information and transactions, always start by \"\n",
    "        \"saying 'Hi this is Steve from drums' {drum_context}\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create the top layer agent that will be used to orchestrate the `handoff`, this agent contains additonal properties such as:\n",
    "- **handoffs**: the handoffs to use for the agent - we will provide the bottom layer agents in here\n",
    "- **handoff_description**: the description of the handoff - this will be used to provide the AI with information about when to handoff etc...\n",
    "\n",
    "We can also import the `RECOMMENDED_PROMPT_PREFIX` from the `handoff_prompt` extension, this will provide the agent with the correct formatting for the handoff defined by the devs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "# top layer agent\n",
    "orchestration_agent = Agent(\n",
    "    name=\"Orchestration agent\", \n",
    "    handoffs=[drums_agent, guitar_agent],\n",
    "    handoff_description=\"For any queries about guitars or drums, handoff to the relevant agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the `Runner` we apply the `run` method to the orchestration agent, this requires us to define the `starting_agent` and the `input` to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=orchestration_agent,\n",
    "    input=\"I want to prices and information about the guitar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `run` method provides us with a `RunResult` object, this contains a list of useful properties listed below:\n",
    "- **input**: the input to the agent\n",
    "- **new_items**: this provides a `HandoffCallItem` object that details all the agents and their associated properties involved in the orchestration agent\n",
    "- **raw_responses**: contains the raw model responses\n",
    "- **final_output**: the final output from the orchestration agent\n",
    "- **input_guardrail_results** and **output_guardrail_results**: these contain the guardrail results for the input and output of the agent\n",
    "- **_last_agent**: this contains the last agent that was called\n",
    "\n",
    "The attributes that we are interested in for this tutorial are the `new_items`, `raw_responses`, `final_output` and `_last_agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item details: \", result.new_items) # details about the handoff\n",
    "print(\"Raw responses: \", result.raw_responses) # the raw model responses\n",
    "print(\"Final output: \", result.final_output) # the final output from the run\n",
    "print(\"Last agent called: \", result._last_agent) # the last agent that was called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then take this a step futher and create a `on_handoff` function that will be called when the handoff is made, this can be useful for noting down the handoff in a database or simply making routine tasks before the handoff is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import RunContextWrapper\n",
    "\n",
    "async def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff Called!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will redefine the orchestration agent, this time we will provide a `handoff` object instead of the agents directly, this allows us to provide additional information such as the `on_handoff` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import handoff\n",
    "\n",
    "# top layer agent\n",
    "orchestration_agent = Agent(\n",
    "    name=\"Orchestration agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoff_description=\"For any queries about guitars, handoff to the guitar agent\",\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=guitar_agent,\n",
    "            on_handoff=on_handoff\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our function we made earlier, we will run the orchestration agent, and if the handoff is made we should see the print statement we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestration_agent,\n",
    "    input=\"I want to prices and information about the guitar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this a step further and create dynamic handoffs, that can encapsulate data and print out to provide reasoning for the handoff.\n",
    "\n",
    "For this we need to create a class that inherits from `BaseModel` from `pydantic`, this is required to pass the `__pydantic_validator__` attribute in the handoff functionallity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class handoff_data(BaseModel):\n",
    "    reason: str\n",
    "\n",
    "async def on_handoff(ctx: RunContextWrapper[None], input_data: handoff_data):\n",
    "    print(f\"Handoff called with reason: {input_data.reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only noteable difference here is the `input_type` parameter, this is used to pass the class we created earlier to the handoff function, this will allow the top layer agent to pass data required to the bottom layer agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top layer agent\n",
    "orchestration_agent = Agent(\n",
    "    name=\"Orchestration agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoff_description=\"For any queries about guitars, handoff to the guitar agent\",\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=guitar_agent,\n",
    "            on_handoff=on_handoff,\n",
    "            input_type=handoff_data\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before if we run the orchestration agent we can see the handoff is made and the reason is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestration_agent,\n",
    "    input=\"I want to prices and information about the guitar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at how to include / exclude tools from the handoff, this can be useful for when we want to handoff to an agent but not provide them with the tools that a top layer agent has.\n",
    "\n",
    "First we need to create a function with the `@function_tool` decorator, this will allow the function to be used as a tool in our orchestration agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_current_time():\n",
    "    return \"time is 7pm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to include this tool in our orchestration agent, we can do this by adding the tool to the `tools` parameter in the orchestration agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top layer agent\n",
    "orchestration_agent = Agent(\n",
    "    name=\"Orchestration agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    tools=[get_current_time],\n",
    "    handoff_description=\"For any queries about guitars, handoff to the guitar agent\",\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=guitar_agent,\n",
    "            on_handoff=on_handoff,\n",
    "            input_type=handoff_data\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this currently we can see the handoff is made..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestration_agent,\n",
    "    input=\"Given the time, how much is an electric guitar?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And currently the tool is available to the guitar agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final output: \", result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to exclude the top layer agent's tools from bottom layer agents we can use the `input_filter` parameter in the handoff function. We can then pass the `remove_all_tools` function from the `handoff_filters` extension. This will remove all tools from the bottom layer agent that was passed via the top agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions import handoff_filters\n",
    "\n",
    "# top layer agent\n",
    "orchestration_agent = Agent(\n",
    "    name=\"Orchestration agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    tools=[get_current_time],\n",
    "    handoff_description=\"For any queries about guitars, handoff to the guitar agent\",\n",
    "    handoffs=[\n",
    "        handoff(\n",
    "            agent=guitar_agent,\n",
    "            on_handoff=on_handoff,\n",
    "            input_type=handoff_data,\n",
    "            input_filter=handoff_filters.remove_all_tools\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we run the agent again we should see the tool is not available to the guitar agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestration_agent,\n",
    "    input=\"Given the time, how much is an electric guitar?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we can see the tool is not available to the guitar agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final output: \", result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
