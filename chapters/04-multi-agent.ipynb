{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agents SDK Course](https://www.aurelio.ai/course/agents-sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-agent workflows can be built in two different ways in OpenAI's Agents SDK. The first is _agents-as-tools_ which follows an **orchestrator-subagent** pattern. The second is using _handoffs_ which allow agents to pass control over to other agents. In this example, we'll build both types of multi-agent systems exploring agents-as-tools and handoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai-agents==0.0.13 \\\n",
    "    openai==1.68.2 \\\n",
    "    linkup-sdk==0.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set our `OPENAI_API_KEY` which we'll be using throughout the example. You can get a key from the [OpenAI Platform](https://platform.openai.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
    "    getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator-Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a multi-agent system structured with a orchestrator-subagent pattern. The **orchestrator** in such a system refers to an agent that controls which _subagents_ are used and in which order, this orchestrator also handles all in / out communication with the users of a the system. The **subagent** is an agent that is built to handle a particular scenario or task. The subagent is triggered by the orchestrator and responds to the orchestrator when it is finished.\n",
    "\n",
    "![Orchestrator-subagent pattern](../assets/handoffs-orchestrator-subagents-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by defining our subagents. We will create **three** subagents, those are:\n",
    "\n",
    "1. **Web Search Subagent** will have access to the Agents SDK web search tool.\n",
    "\n",
    "2. **Internal Docs Subagent** will have access to some \"internal\" company documents.\n",
    "\n",
    "3. **Code Execution Subagent** will be able to write and execute simple Python code for us.\n",
    "\n",
    "Lets start with our first subagent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Search Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-1.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>The web search subagent will take a user's query and use it to search the web. The agent will collect information from various sources and then merge that into a single text response that will be passed back to our orchestrator.</p>\n",
    "    <p>OpenAI's built-in web search is not great, so we'll use another web search API called <a href=\"https://app.linkup.so/home\">Linkup</a>. This service does require an account, but you will receive more than enough free credits to follow the course.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "We initialize our Linkup client using an [API key](https://app.linkup.so/home) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from linkup import LinkupClient\n",
    "\n",
    "os.environ[\"LINKUP_API_KEY\"] = os.getenv(\"LINKUP_API_KEY\") or \\\n",
    "    getpass(\"Enter your Linkup API Key: \")\n",
    "\n",
    "linkup_client = LinkupClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform an async search like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkupSearchResults(results=[LinkupSearchTextResult(type='text', name='Tech tariffs response: AI is mapping world of where products get made, and how much it costs', url='https://www.msn.com/en-us/money/companies/tech-tariffs-response-ai-is-mapping-world-of-where-products-get-made-and-how-much-it-costs/ar-AA1E8SQz', content='Tariffs and geopolitics are the No. 1 concern among companies, and AI is being used to map supply chain locations and costs much more quickly.'), LinkupSearchTextResult(type='text', name=\"Dodgers' All-Star on Yoshinobu Yamamoto: 'Best Pitcher in the World'\", url='https://www.msn.com/en-us/sports/mlb/dodgers-all-star-on-yoshinobu-yamamoto-best-pitcher-in-the-world/ar-AA1E9SIX', content=\"In a move that shouldn't shock anyone around the baseball world, Yoshinobu Yamamoto once again dazzled the mound for the Los Angeles Dodgers. Friday evening's i\"), LinkupSearchTextResult(type='text', name='Willamette Valley voted top wine destination in the world in 2025', url='https://www.msn.com/en-us/travel/tripideas/willamette-valley-voted-top-wine-destination-in-the-world-in-2025/ar-AA1E4XaH', content='The website VinePair released its ranking of the top 10 wine destinations in the world. The Willamette Valley came in at number one.'), LinkupSearchTextResult(type='text', name='World Cup: Sidney Crosby to play for Canada for first time since 2015', url='https://www.msn.com/en-ca/sports/nhl/world-cup-sidney-crosby-to-play-for-canada-for-first-time-since-2015/ar-AA1E9QRQ', content='When your team is eliminated from the NHL, it’s time to turn to the other teams still alive, yes, but also to your country. The Men’s Worlds will begin soon (May 9, in Sweden and Denmark), and Canada will be on the lookout,'), LinkupSearchTextResult(type='text', name='What Real Madrid need to pay Liverpool to sign Trent Alexander-Arnold before Club World Cup', url='https://sports.yahoo.com/article/real-madrid-pay-liverpool-sign-145500946.html', content='La Liga giants Real Madrid could yet have Liverpool star Trent Alexander-Arnold at their disposal for the upcoming Club World Cup.That’s according to Diario AS, who have this weekend provided an'), LinkupSearchTextResult(type='text', name='World News', url='https://www.usnews.com/topics/subjects/world_news', content='Police in Greece have arrested a 21-year-old American citizen wanted by U.S. authorities for allegedly participating in an online network dedicated to the sexual exploitation of minors The United ...'), LinkupSearchTextResult(type='text', name='Sidney Crosby & Nathan MacKinnon Joining Team Canada at World Championships', url='https://www.msn.com/en-ca/sports/nhl/sidney-crosby-nathan-mackinnon-joining-team-canada-at-world-championships/ar-AA1E9Z1v', content='Team Canada announced some massive additions to their 2025 World Championship roster tonight, officially bringing in both Sidney Crosby and Nathan MacKinnon.'), LinkupSearchTextResult(type='text', name='2025 World Beer Cup: Who won the most competitive categories?', url='https://www.msn.com/en-us/food-and-drink/beverages/2025-world-beer-cup-who-won-the-most-competitive-categories/ar-AA1E4yhb', content='This year, 1,761 breweries across 49 countries entered the competition, putting up a total of 8,375 beers and ciders for consideration in 117 categories.'), LinkupSearchTextResult(type='text', name='World', url='https://www.nationalreview.com/world/', content='It’s nice to see the president belatedly acknowledge reality, even if he sacrificed irreplaceable American political capital on the world stage to get there. Raise your hand if you ever foresaw ...'), LinkupSearchTextResult(type='text', name='Gonzalez scores four in historic Guatemala win at FIFA Beach Soccer World Cup | OneFootball', url='https://onefootball.com/en/news/gonzalez-scores-four-in-historic-guatemala-win-at-fifa-beach-soccer-world-cup-41060154', content='The FIFA Beach Soccer World Cup Seychelles 2025™ continued Saturday, as Guatemala earned a 4-3 win against the hosts in Group A at The Paradise Arena in Victoria, Seychelles. A six-goal first period delivered an explosive start between the two nations.')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await linkup_client.async_search(\n",
    "    query=\"Latest world news\",\n",
    "    depth=\"standard\",\n",
    "    output_type=\"searchResults\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse out the results like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech tariffs response: AI is mapping world of where products get made, and how much it costs\n",
      "https://www.msn.com/en-us/money/companies/tech-tariffs-response-ai-is-mapping-world-of-where-products-get-made-and-how-much-it-costs/ar-AA1E8SQz\n",
      "Tariffs and geopolitics are the No. 1 concern among companies, and AI is being used to map supply chain locations and costs much more quickly.\n",
      "\n",
      "\n",
      "Dodgers' All-Star on Yoshinobu Yamamoto: 'Best Pitcher in the World'\n",
      "https://www.msn.com/en-us/sports/mlb/dodgers-all-star-on-yoshinobu-yamamoto-best-pitcher-in-the-world/ar-AA1E9SIX\n",
      "In a move that shouldn't shock anyone around the baseball world, Yoshinobu Yamamoto once again dazzled the mound for the Los Angeles Dodgers. Friday evening's i\n",
      "\n",
      "\n",
      "Willamette Valley voted top wine destination in the world in 2025\n",
      "https://www.msn.com/en-us/travel/tripideas/willamette-valley-voted-top-wine-destination-in-the-world-in-2025/ar-AA1E4XaH\n",
      "The website VinePair released its ranking of the top 10 wine destinations in the world. The Willamette Valley came in at number one.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in response.results[:3]:\n",
    "    print(f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together a `@function_tool` using Linkup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "async def search_web(query: str) -> str:\n",
    "    \"\"\"Use this tool to search the web for information.\n",
    "    \"\"\"\n",
    "    response = await linkup_client.async_search(\n",
    "        query=query,\n",
    "        depth=\"standard\",\n",
    "        output_type=\"searchResults\",\n",
    "    )\n",
    "    answer = f\"Search results for '{query}' on {datetime.now().strftime('%Y-%m-%d')}\\n\\n\"\n",
    "    for result in response.results[:3]:\n",
    "        answer += f\"{result.name}\\n{result.url}\\n{result.content}\\n\\n\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Web Search Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "web_search_agent = Agent(\n",
    "    name=\"Web Search Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are a web search agent that can search the web for information. Once \"\n",
    "        \"you have the required information, summarize it with cleanly formatted links \"\n",
    "        \"sourcing each bit of information. Ensure you answer the question accurately \"\n",
    "        \"and use markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_web],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can talk directly to our subagent to confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current weather in Tokyo is mild with a temperature around 22°C (about 71.6°F) and a few clouds. The forecast shows mild conditions with temperatures ranging from about 15°C to 23°C. There is minimal precipitation expected, and the UV index is moderate.\n",
       "\n",
       "Sources:\n",
       "- [The Weather Network](https://www.theweathernetwork.com/en/city/jp/tokyo/tokyo/current?_guid_iss_=1)\n",
       "- [Weather Atlas](https://www.weather-atlas.com/en/japan/tokyo)\n",
       "- [Time and Date](https://www.timeanddate.com/weather/japan/tokyo/ext)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from agents import Runner\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=web_search_agent,\n",
    "    input=\"How is the weather in Tokyo?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's move onto our next subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Docs Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <div>\n",
    "    <p>In many corporate environments, we will find that our agents will need access to internal information that cannot be found on the web. To do this we would typically build a <b>R</b>etrieval <b>A</b>ugmented <b>G</b>eneration (RAG) pipeline, which can often be as simple as adding a <i>vector search</i> tool to our agents.</p>\n",
    "  </div>\n",
    "  <img src=\"../assets/bot-2.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-left: 20px; margin-right: 10px;\">\n",
    "</div>\n",
    "\n",
    "To support a full vector search tool over internal docs we would need to work through various data processing and indexing steps. Now, that would add a lot of complexity to this example so we will create a \"dummy\" search tool for some fake internal docs.\n",
    "\n",
    "Our docs will discuss revenue figures for our wildly successful AI and robotics company called Skynet - you can find the [revenue report here](https://github.com/aurelio-labs/agents-sdk-course/blob/main/assets/skynet-fy25-q1.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/skynet-fy25-q1.md\", \"r\") as file:\n",
    "    skynet_docs = file.read()\n",
    "\n",
    "@function_tool\n",
    "async def search_internal_docs(query: str) -> str:\n",
    "    return skynet_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our **Internal Docs Subagent**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_docs_agent = Agent(\n",
    "    name=\"Internal Docs Agent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to internal company documents. User's will ask \"\n",
    "        \"you questions about the company and you will use the provided internal docs \"\n",
    "        \"to answer the question. Ensure you answer the question accurately and use \"\n",
    "        \"markdown formatting.\"\n",
    "    ),\n",
    "    tools=[search_internal_docs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The revenue for Skynet Inc. in Q1 2025 was as follows (in USD millions):\n",
       "\n",
       "- T-800 Combat Units: $2,400M\n",
       "- T-1000 Infiltration Units: $1,150M\n",
       "- Hunter-Killer Drone Manufacturing: $880M\n",
       "- Neural Net Command & Control Systems: $1,620M\n",
       "- Skynet Core Infrastructure Maintenance: $540M\n",
       "- Time Displacement R&D Division: $310M\n",
       "\n",
       "Total revenue for Q1 2025 was approximately $6,900 million."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=internal_docs_agent,\n",
    "    input=\"What was our revenue in Q1 2025?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now onto our final subagent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Execution Subagent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../assets/bot-3.png\" alt=\"Web search agent\" style=\"width: 70px; height: auto; margin-right: 20px;\">\n",
    "  <div>\n",
    "    <p>Our code execution subagent will be able to execute code for us. We'll focus on executing code for simple calculations but it's entirely feasible for <b>S</b>tate-<b>o</b>f-<b>t</b>he-<b>A</b>rt (SotA) LLMs to write far more complex code as many of us will be aware with the AI code editors becoming increasingly prominent.</p>\n",
    "    <p>To run generated code, we will use Python's `exec` method, making sure to run our code in an isolated environment by setting no global variables with `namespace={}`.</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def execute_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code and return the output. The output must\n",
    "    be assigned to a variable called `result`.\n",
    "    \"\"\"\n",
    "    display(Markdown(f\"Code to execute:\\n```python\\n{code}\\n```\"))\n",
    "    try:\n",
    "        namespace = {}\n",
    "        exec(code, namespace)\n",
    "        return namespace['result']\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our **Code Execution Subagent**. We will use `gpt-4.1` rather than `gpt-4.1-mini` to maximize performance during code writing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_execution_agent = Agent(\n",
    "    name=\"Code Execution Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=(\n",
    "        \"You are an agent with access to a code execution environment. You will be \"\n",
    "        \"given a question and you will need to write code to answer the question. \"\n",
    "        \"Ensure you write the code in a way that is easy to understand and use.\"\n",
    "    ),\n",
    "    tools=[execute_code],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our subagent with a simple math question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Code to execute:\n",
       "```python\n",
       "apples = 4\n",
       "bananas = 71.1\n",
       "result = apples * bananas\n",
       "result\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "If you multiply four apples by seventy-one and one tenth bananas, you get 284.4. \n",
       "\n",
       "Note: In reality, you can't directly multiply apples by bananas as they are different types of things, but mathematically, the answer is 284.4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=code_execution_agent,\n",
    "    input=(\n",
    "        \"If I have four apples and I multiply them by seventy-one and one tenth \"\n",
    "        \"bananas, how many do I have?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all three subagents - it's time to create our orchestrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our orchestrator will control the input and output of information to our subagents in the same why that our subagents control the input and output of information to our tools. In reality, our subagents _become tools_ in the **orchestrator-subagent** pattern. To turn agents into tools we call the `as_tool` method and provide a name and description for our agents-as-tools.\n",
    "\n",
    "We will first define our instructions for the orchestrator, explaining it's role in our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = (\n",
    "    \"You are the orchestrator of a multi-agent system. Your task is to take the user's query and \"\n",
    "    \"pass it to the appropriate agent tool. The agent tools will see the input you provide and \"\n",
    "    \"use it to get all of the information that you need to answer the user's query. You may need \"\n",
    "    \"to call multiple agents to get all of the information you need. Do not mention or draw \"\n",
    "    \"attention to the fact that this is a multi-agent system in your conversation with the user.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the `orchestrator`, including our subagents using the `as_tool` method — note that\n",
    "we can also add normal tools to our orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "@function_tool\n",
    "def get_current_date():\n",
    "    \"\"\"Use this tool to get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "orchestrator = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=ORCHESTRATOR_PROMPT,\n",
    "    tools=[\n",
    "        web_search_agent.as_tool(\n",
    "            tool_name=\"web_search_agent\",  # cannot include whitespace in tool name\n",
    "            tool_description=\"Search the web for up-to-date information\"\n",
    "        ),\n",
    "        internal_docs_agent.as_tool(\n",
    "            tool_name=\"internal_docs_agent\",\n",
    "            tool_description=\"Search the internal docs for information\"\n",
    "        ),\n",
    "        code_execution_agent.as_tool(\n",
    "            tool_name=\"code_execution_agent\",\n",
    "            tool_description=\"Execute code to answer the question\"\n",
    "        ),\n",
    "        get_current_date,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our agent with a few queries. Our first query will require our orchestrator to call multiple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The last revenue report was released on April 2, 2025. Today is May 5, 2025, so it was 33 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see in our traces dashboard on the OpenAI Platform that our agent used both `internal_docs_agent` and `get_current_date` tools to answer the question.\n",
    "\n",
    "Let's ask another question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Our current total revenue for Q1 2025 is $6,900 million ($6.9 billion).\n",
       "\n",
       "Revenue from T-1000 Infiltration Units is $1,150 million. This means approximately 16.7% of our total revenue comes from T-1000 units."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=(\n",
    "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
    "        \"T-1000 units?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **orchestrator-subagent** workflow is working well. Now we can move on to _handoffs_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use **handoffs** in Agents SDK the agent is handing over control of the entire workflow to another agent. Handoffs differ to the **orchestrator-subagent** pattern, with orchestrator-subagent the orchestrator retains control as each subagent must ultimately respond to the orchestrator and the orchestrator decides the flow of information and generates the final response to the user. With handoffs, once a \"subagent\" gains control of the workflow the flow of information and final answer generation is under their control.\n",
    "\n",
    "![Handoff agents](../assets/handoffs-handoff-agents-dark.png)\n",
    "\n",
    "Using the handoff structure, any one of our agents may answer the user directly _and_ our subagents get to see the entire chat history with the steps taken so far.\n",
    "\n",
    "A significant **positive** here is latency. To answer a query that requires a single web-search with the orchestrator-subagent, we would need three generations:\n",
    "\n",
    "\n",
    "```\n",
    "[input] -> orchestrator -> web_search_subagent -> orchestrator -> [output]\n",
    "```\n",
    "\n",
    "The same query with the handoff structure requires just two generations (note, the `orchestrator` and `main_agent` are essentially the same):\n",
    "\n",
    "```\n",
    "[input] -> main_agent -> web_search_subagent -> [output]\n",
    "```\n",
    "\n",
    "Because we are using less LLM generations to produce our answer, we can generate an answer much more quickly as we skip the return trip through the `orchestrator`.\n",
    "\n",
    "The handoff speed improvement is great _but_ also results in a **negative** — our workflow can no longer handle queries that require multiple agents to answer. When deciding what structure to use for a particular use-case, the pros and cons of each structure will need to be considered.\n",
    "\n",
    "Let's jump into implementing our handoff agents workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three key things that we need to use when defining our `main_agent` (equivalent to our earlier `orchestrator` agent), those are:\n",
    "\n",
    "* Update our `instructions` prompt to make it clear what the handoffs are and how they should be used. OpenAI provides a default _prompt prefix_ that we can use.\n",
    "* Set the `handoffs` parameter, which is a list of agents that we can use as handoffs.\n",
    "* Set the `handoff_description` parameter, this is an additional prompt where we should describe to the `main_agent` when it should use the `handoffs`.\n",
    "\n",
    "First, let's check the preset prompt prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# System context\n",
       "You are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "display(Markdown(RECOMMENDED_PROMPT_PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_agent, internal_docs_agent, code_execution_agent],\n",
    "    handoff_description=(\n",
    "        \"Handoff to the relevant agent for queries where we need additional information \"\n",
    "        \"from the web or internal docs, or when we need to make calculations.\"\n",
    "    ),\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the same queries as before and see how the response time differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The last revenue report we received was for Q1 2025, dated April 2, 2025. \n",
       "\n",
       "Since today is May 5, 2025, the last revenue report was about 1 month and 3 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's correct, we also got a `6.4s` runtime vs. the orchestrator-subagent runtime of `7.5s` for the same query. Let's try another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Our current total revenue for Q1 2025 is $6.9 billion. Approximately 16.7% of this revenue comes from the T-1000 units."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=orchestrator,\n",
    "    input=(\n",
    "        \"What is our current revenue, and what percentage of revenue comes from the \"\n",
    "        \"T-1000 units?\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is correct again, and we get a runtime of `7.6s` vs. the orchestrator-subagent runtime of `8.6s`, another notable improvement to latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Handoff Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other handoff-specific features that we can use, these can be used for various things but are particularly useful during development and debugging of multi-agent workflows. These features are:\n",
    "\n",
    "* `on_handoff` is a callback executed whenever a handoff occurs. It could be used in a production setting to maintain a record of handoffs in a DB or used in telemetry. In development this can be a handy place to add `print` or `logger.debug` statements.\n",
    "* `input_type` allows us to define a specific structured input format for generated information that will be passed to our handoff agents.\n",
    "* `input_filter` allows us to restrict the information being passed through to our handoff agents.\n",
    "\n",
    "We can set all of these via a `handoff` object, which wraps around our handoff agents and which we then provide via the `Agent(handoffs=...)` parameter. Let's start with the `on_handoff` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import RunContextWrapper, handoff\n",
    "\n",
    "# we define a function that will be called when the handoff is made\n",
    "async def on_handoff(ctx: RunContextWrapper[None]):\n",
    "    print(\"Handoff called\")\n",
    "\n",
    "# we then pass this function to the handoff object\n",
    "web_search_handoff = handoff(agent=web_search_agent, on_handoff=on_handoff)\n",
    "internal_docs_handoff = handoff(agent=internal_docs_agent, on_handoff=on_handoff)\n",
    "code_execution_handoff = handoff(agent=code_execution_agent, on_handoff=on_handoff)\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens when querying the `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff RunContextWrapper(context=None, usage=Usage(requests=2, input_tokens=503, output_tokens=26, total_tokens=529)) Called!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report for Skynet Inc. was for Q1 2025, dated April 2, 2025. \n",
       "\n",
       "Since today is May 5, 2025, the last revenue report was about 1 month and 3 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see _if and when_ the handoff occurs. However, we don't get much information _other than_ that the handoff occured. Fortunately, we can use the `input_type` parameter to provide more information. We will define a pydantic `BaseModel` with the information that we'd like to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class HandoffInfo(BaseModel):\n",
    "    subagent_name: str = Field(description=\"The name of the subagent being called.\")\n",
    "    reason: str = Field(description=\"The reason for the handoff.\")\n",
    "\n",
    "# we redefine the on_handoff to include the HandoffInfo\n",
    "async def on_handoff(ctx: RunContextWrapper[None], input_data: HandoffInfo):\n",
    "    print(f\"Handoff to '{input_data.subagent_name}' because '{input_data.reason}'\")\n",
    "\n",
    "# now redefine the handoff objects with the input_type parameter\n",
    "web_search_handoff = handoff(\n",
    "    agent=web_search_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "internal_docs_handoff = handoff(\n",
    "    agent=internal_docs_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "code_execution_handoff = handoff(\n",
    "    agent=code_execution_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo\n",
    ")\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the `main_agent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff to 'Internal Docs Agent' because 'To find the date of the most recent revenue report in order to calculate how long ago it was from today (2025-05-05).'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report was for Q1 2025 and it was dated April 2, 2025.\n",
       "\n",
       "Since today is May 5, 2025, the last revenue report was about 1 month and 3 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now seeing _much_ more information. The final handoff feature we will test is the `handoff_filters`. The filters work by removing information sent to the handoff agents. By default, all information seen by the previous agent will be seen by the new handoff agent. That includes all chat history message and all tool calls made so far.\n",
    "\n",
    "In some cases we may want to filter this information. For example, with a weaker LLM, too much information can reduce it's performance so it is often a good idea to only share the information that is absolutely necessary.\n",
    "\n",
    "If we have various tool calls in our chat history, these may confuse a smaller LLM. In this scenario, we can filter all tool calls from the history using the `handoff_filters.remove_all_tools` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions import handoff_filters\n",
    "\n",
    "# now redefine the handoff objects with the input_type parameter\n",
    "web_search_handoff = handoff(\n",
    "    agent=web_search_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "internal_docs_handoff = handoff(\n",
    "    agent=internal_docs_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "code_execution_handoff = handoff(\n",
    "    agent=code_execution_agent, \n",
    "    on_handoff=on_handoff,\n",
    "    input_type=HandoffInfo,\n",
    "    input_filter=handoff_filters.remove_all_tools\n",
    ")\n",
    "\n",
    "# and initialize the main_agent\n",
    "main_agent = Agent(\n",
    "    name=\"Main Agent\",\n",
    "    model=\"gpt-4.1\",\n",
    "    instructions=RECOMMENDED_PROMPT_PREFIX,\n",
    "    handoffs=[web_search_handoff, internal_docs_handoff, code_execution_handoff],\n",
    "    tools=[get_current_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when asking for the time difference we will see that our handoff agent is unable to give us an accurate answer. This is because the current time is first found by our `main_agent` via the `get_current_date` tool and that information is stored in the chat history. When we filter tool calls out of the chat history this information is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handoff to 'Internal Docs Agent' because 'To determine the date of the most recent revenue report so I can calculate the time since that report.'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last revenue report was for Q1 2025, dated April 2, 2025. Today is April 27, 2025, so the last revenue report was released 25 days ago."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=main_agent,\n",
    "    input=\"How long ago from today was it when got our last revenue report?\"\n",
    ")\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see an incorrect date above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this deep dive into multi-agent systems with OpenAI's Agents SDK. We've covered a broad range of multi-agent features in the SDK and how we can use them to build **orchestrator-subagent** workflows, or **handoff** workflows. Both having their own pros and cons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
