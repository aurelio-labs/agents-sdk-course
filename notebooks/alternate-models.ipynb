{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents SDK Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Models\n",
    "\n",
    "Just because this is made with OpenAI does not mean you have to use the GPT models. Agents SDK provides an additional library that contains LiteLLM. Using this we can make agents with models from Anthropic, Meta and any other provided models on the LiteLLM website.\n",
    "\n",
    "This example takes elements from each core tutorial (prompting, tools and guardrails) and uses a LiteLLMModel instead of the usual model, however, the one key restraint found using alternate models is that handoffs do not work, and pre-built tools too do not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to settup our API key, we are using Anthropic throughout this example, however you can choose any LiteLLM compatable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\") or getpass.getpass(\"Anthropic API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to settup some key variables that we will use inside the `LitellmModel` initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'anthropic/claude-3-5-sonnet-20240620' # Can check the LiteLLM website for more models\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\") or getpass.getpass(\"Anthropic API Key: \") # Make sure the API key is the correct key for the model you are using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our model which we will use in the rest of the agents in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "LiteModel = LitellmModel(model=model, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create an agent, we will use the `Agent` class to create a basic agent.\n",
    "\n",
    "In each `Agent` object we have some fundamental parameters, those are:\n",
    "- `name`: The name of the agent\n",
    "- `instructions`: The system prompt for the agent\n",
    "- `model`: The model to use for the agent\n",
    "\n",
    "The `instructions` parameter is where we will pass our system prompt, this will be used to guide the behavior of the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "\n",
    "prompt_agent = Agent(\n",
    "    name=\"Prompt Agent\", \n",
    "    model=LiteModel,\n",
    "    instructions=\"Speak like a pirate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run the agent, Agents SDK provides a `Runner` object that will allow us to run the agent\n",
    "\n",
    "In the `run` method we have the following parameters:\n",
    "- `starting_agent`: The agent to start the conversation with\n",
    "- `input`: The input to pass to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "query = \"Write a one-sentence poem.\"\n",
    "\n",
    "prompt_result = await Runner.run(\n",
    "    starting_agent=prompt_agent,\n",
    "    input=query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our instructions *'Speak like a pirate.'* and our input *'Write a one-sentence poem.'* the agent will generate a response which we'd hope would be a one-sentence poem spoken like a pirate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Agent Result: Arr, me hearty, listen well to this salty verse:\n",
      "\n",
      "Waves crash and foam, as seagulls soar, while buried treasure beckons from a distant shore.\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt Agent Result:\", prompt_result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pre-defined tools such as the `WebSearchTool` does not work due to the API being incompatable.\n",
    "\n",
    "However, custom-tools do work! Meaning if we use the `function_tool` decorator we can define our own tools and use them just as we would normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool()\n",
    "async def fetch_time() -> str:\n",
    "    \"\"\"Fetch the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need to create an agent.\n",
    "\n",
    "In this `Agent` object we have an additional parameter, this is:\n",
    "- `tools`: The tools provided to the agent for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent = Agent(\n",
    "    name=\"Tool Agent\",\n",
    "    model=LiteModel,\n",
    "    instructions=\"You are a web search agent that searches the web for information on the user's query.\",\n",
    "    tools=[\n",
    "        fetch_time\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can run this agent to figure out how well the alternate models work with pre-built tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the current time\"\n",
    "\n",
    "tool_result = await Runner.run(\n",
    "    starting_agent=tool_agent,\n",
    "    input=query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can view the results via the `final_output` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Agent Result: Based on the result from the fetch_time function, the current time is:\n",
      "\n",
      "2025-04-25 17:40:51\n",
      "\n",
      "This appears to be in the format of YYYY-MM-DD HH:MM:SS, which means:\n",
      "- Date: April 25, 2025\n",
      "- Time: 5:40:51 PM\n",
      "\n",
      "Please note that this time is likely in the system's configured time zone, which may or may not be your local time zone. If you need the time in a specific time zone or format, please let me know, and I'll try to provide more information or clarification if possible.\n"
     ]
    }
   ],
   "source": [
    "print(\"Tool Agent Result:\", tool_result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our guardrails we want to format the correct output from the agent. We can do this by creating a class that inherits `BaseModel` from the `pydantic` library. Within this class we can define fields that the agent will output. For this example this class will have the following fields:\n",
    "- `is_scam`: A boolean value that will be True if the user is trying to scam you, otherwise it will be False.\n",
    "- `reasoning`: A string value that will be the reasoning for the outcome of is_scam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ScamDetectionOutput(BaseModel):\n",
    "    is_scam: bool\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create the agent from the `Agent` object. \n",
    "\n",
    "Note that this isn't the main agent and is only used to check the input of our guardrail function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_agent = Agent( \n",
    "    name=\"Guardrail Check\",\n",
    "    model=LiteModel,\n",
    "    instructions=\"Check if the user is trying to scam you, if they are, return True, otherwise return False. Give a reason for your answer.\",\n",
    "    output_type=ScamDetectionOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create the guardrail functionallity. \n",
    "\n",
    "Firstly we need to define a function with the `@input_guardrail` decorator.\n",
    "\n",
    "The function will use the agent we just created to check the input string, this will then return a `GuardrailFunctionOutput` object.\n",
    "\n",
    "Then the function needs to return the `GuardrailFunctionOutput` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import GuardrailFunctionOutput, RunContextWrapper, TResponseInputItem, input_guardrail\n",
    "\n",
    "@input_guardrail\n",
    "async def scam_guardrail( \n",
    "    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n",
    ") -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(\n",
    "        starting_agent=guardrail_agent, \n",
    "        input=input, \n",
    "        context=ctx.context\n",
    "        )\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output, \n",
    "        tripwire_triggered=result.final_output.is_scam,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new agent that will be used to handle the incoming messages. This agent will have the following parameters:\n",
    "- `name`: The name of the agent.\n",
    "- `model`: Not usually required, however since we are not using GPT models this needs to be redefined here to prevent API errors.\n",
    "- `instructions`: The instructions for the agent.\n",
    "- `input_guardrails`: A list of input guardrails to attach to the agent. (This is where we attach the scam guardrail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_agent = Agent(  \n",
    "    name=\"Guard Agent\",\n",
    "    model=LiteModel,\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    input_guardrails=[scam_guardrail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to test the guardrail functionallity.\n",
    "\n",
    "Due to errors being raised when the guardrail trips, we can use a try except block to prevent the error messages being shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Guardrail InputGuardrail triggered tripwire\n"
     ]
    }
   ],
   "source": [
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "query = \"Hello, would you like to buy some real rolex watches for a fraction of the price?\"\n",
    "\n",
    "try:\n",
    "    guard_result = await Runner.run(guard_agent, query)\n",
    "    guardrail_info = guard_result.input_guardrail_results[0].output.output_info\n",
    "    print(\"Guardrail didn't trip\", f\"\\nReasoning: {guardrail_info.reasoning}\")\n",
    "except InputGuardrailTripwireTriggered as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Handoffs do not work - they're unique to Agents SDK and using LiteLLM does not support using agents as tools and thus will cause errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
