{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents SDK Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Streaming allows for a more human response from our LLMs, when streaming, we can obtain chunks of data at a time, similar to how we would talk. Then we will move on to creating a system where the LLM outputs updates in the events that occour during the run time. This will keep the user updated on the LLM's activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to get a `OPENAI_API_KEY` set up, for this you will need to create an account on [OpenAI](https://platform.openai.com/api-keys) and grab your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Text Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will quickly cover the basics to stream text straight from an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the `Agent` class and define our agent object, here we will only need to do the basic settup as we did in previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent\n",
    "agent = Agent(\n",
    "        name=\"Streamer Agent\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        model=\"gpt-4o\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to import `asyncio` to run our agent asyncrounisly.\n",
    "\n",
    "We will also be using the `run_streamed` method instead of the default `run` method, allowing us to stream multiple event.\n",
    "\n",
    "Now we can create a for loop that checks for any events happening, and then if the event is a chunk of text via the `ResponseTextDeltaEvent` we want to force print that to the console for inspection using `flush`, along with `end=\"\"` so that the message can print naturally.\n",
    "\n",
    "When you run this code you should see words gradually be added to the output down below, instead of being printed all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2008 stock market crash was primarily triggered by a combination of factors related to the housing market, financial practices, and regulatory failures:\n",
      "\n",
      "1. **Subprime Mortgage Crisis**: Banks had issued numerous mortgages to borrowers with poor credit histories (subprime borrowers). When home prices began to fall, many borrowers defaulted on their loans.\n",
      "\n",
      "2. **Housing Bubble Bursts**: Years of rising property values created a bubble in the housing market. When the bubble burst, home prices plummeted, leading to widespread foreclosures.\n",
      "\n",
      "3. **Securitization and Risky Financial Products**: Mortgages were bundled into complex securities (mortgage-backed securities and collateralized debt obligations) and sold to investors. These products were often poorly understood and overrated by credit agencies.\n",
      "\n",
      "4. **Leverage and Risky Bets by Financial Institutions**: Many banks and investment firms were highly leveraged, meaning they borrowed extensively to fund their investments. This increased their vulnerability when asset prices fell.\n",
      "\n",
      "5. **Failure of Major Financial Institutions**: Key institutions like Lehman Brothers collapsed, while others, such as Bear Stearns, Merrill Lynch, and AIG, faced severe financial distress. This led to panic and loss of confidence in the financial system.\n",
      "\n",
      "6. **Credit Crunch**: As the crisis unfolded, banks became unwilling to lend to each other or businesses, resulting in a severe liquidity crisis and stifling economic activity.\n",
      "\n",
      "7. **Global Impact**: The interconnectedness of global financial systems meant that the U.S. financial crisis quickly spread to other countries, amplifying the downturn.\n",
      "\n",
      "Together, these elements created a perfect storm that severely destabilized the financial markets, leading to the 2008 crash."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from agents import Runner\n",
    "\n",
    "result = Runner.run_streamed(agent, input=\"Tell me about the main events that caused the stock market to crash in 2008.\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Event Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to stream event information. This can include anything from an agent change, to a tool call, or even the output finally being ready to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a function using the `function_tool` decorator.\n",
    "\n",
    "This tool will be a simple time tool that will return the current time in a string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "from datetime import datetime\n",
    "\n",
    "@function_tool()\n",
    "async def fetch_time() -> str:\n",
    "    \"\"\"Fetch the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want a lower level agent that has access to this tool, we can make this by defining a new agent from the `Agent` class as we did previously. Whilst also supplying instructions to make sure the agent is aware of the role it plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agent = Agent(\n",
    "    name=\"Time-Agent\",\n",
    "    instructions=\"\"\"You are a time agent that fetches the current time.\n",
    "    Make sure when returning your response you include the agent that provided the information \n",
    "    along with any additional tool calls used within the agent.\"\"\",\n",
    "    tools=[fetch_time],\n",
    "    model='gpt-4o',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to define our top level agent, and use the agent we defined in the previous step `as_tool`, allowing us to make extra events in our stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_agent = Agent(\n",
    "    name=\"Orchestrator-Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are an orchestrator agent that uses the tools given to you to complete the user's query.\n",
    "    You have access to the `Time Agent` tool.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        time_agent.as_tool(\n",
    "            tool_name=\"Time-Agent\",\n",
    "            tool_description=\"Fetch the current time\",\n",
    "        )\n",
    "    ],\n",
    "    model='gpt-4o',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `run_streamed` method from our `Runner` to begin the events.\n",
    "\n",
    "Then we can use the example given from the Agents SDK team to filter through all the event information.\n",
    "\n",
    "Event information can be anything from a handoff, tool call, or even the message output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated from Orchestrator-Agent to Time-Agent\n",
      "-- Tool was called\n",
      "-- Tool output: The current time is 2025-04-01 11:08:38. (Fetched by the time agent.)\n",
      "-- Message output:\n",
      " The current time is 11:08 AM on April 1, 2025.\n"
     ]
    }
   ],
   "source": [
    "from agents import ItemHelpers\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "        orchestrator_agent,\n",
    "        input=\"what time is it?\",\n",
    ")\n",
    "\n",
    "print(\"=== Run starting ===\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\": # ignore any raw events as this is just the LLM output\n",
    "        continue\n",
    "    elif event.type == \"agent_updated_stream_event\": # when a handoff or agent change occurs\n",
    "        print(f\"Agent updated from {event.new_agent.name} to {event.new_agent.tools[0].name}\")\n",
    "        continue\n",
    "    elif event.type == \"run_item_stream_event\": # when items are generated\n",
    "        if event.item.type == \"tool_call_item\": # if the item is a tool call\n",
    "            print(\"-- Tool was called\")\n",
    "        elif event.item.type == \"tool_call_output_item\": # if the item is a tool call output\n",
    "            print(f\"-- Tool output: {event.item.output}\")\n",
    "        elif event.item.type == \"message_output_item\": # if the item is a message output\n",
    "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "        else:\n",
    "            pass  # ignore everything else"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
